{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZZf-fbj50Kqc"
      },
      "source": [
        "# Imports"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q jupyternotify\n",
        "!pip install -q tensorflow_text\n",
        "!pip install -q tqdm\n",
        "!pip install -q wandb --upgrade\n",
        "!pip install flopco-keras"
      ],
      "metadata": {
        "id": "PBAoO1bCUGLm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "gather": {
          "logged": 1644854036589
        },
        "id": "MsfMr-Qod_nl",
        "outputId": "e09897f8-e611-4818-b6b6-adf1e370cccf"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "if (!(\"Notification\" in window)) {\n",
              "    alert(\"This browser does not support desktop notifications, so the %%notify magic will not work.\");\n",
              "} else if (Notification.permission !== 'granted' && Notification.permission !== 'denied') {\n",
              "    Notification.requestPermission(function (permission) {\n",
              "        if(!('permission' in Notification)) {\n",
              "            Notification.permission = permission;\n",
              "        }\n",
              "    })\n",
              "}\n"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "# standart liberies:\n",
        "from typing import Optional, List, Set, Dict, Tuple\n",
        "import datetime\n",
        "import os\n",
        "import csv\n",
        "import random\n",
        "import statistics\n",
        "import math\n",
        "import time\n",
        "import sys\n",
        "from functools import lru_cache, reduce\n",
        "# NOT-standart liberies:\n",
        "from flopco_keras import FlopCoKeras  # flop counter for keras at https://github.com/evgps/flopco-keras\n",
        "import wandb\n",
        "import platform\n",
        "import tensorflow as tf\n",
        "import tensorflow_text as tf_text\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import numpy as np\n",
        "import tqdm\n",
        "import matplotlib.pyplot as plt\n",
        "%load_ext jupyternotify"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "gather": {
          "logged": 1644854037100
        },
        "id": "SzaglEQ-kp2n",
        "outputId": "5b7fd3b9-3369-431c-b516-bde95519988f",
        "pycharm": {
          "name": "#%%\n"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Python version: 3.7.13 (default, Apr 24 2022, 01:04:09) \n",
            "[GCC 7.5.0]\n",
            "Tensorflow version: 2.9.1\n",
            "tf text version: 2.9.0\n"
          ]
        }
      ],
      "source": [
        "print(f\"Python version: {sys.version}\")\n",
        "print(f\"Tensorflow version: {tf.__version__}\")\n",
        "print(f\"tf text version: {tf_text.__version__}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rJGjWnfTc6DI",
        "outputId": "c7472bec-3c99-4222-eba6-229027c5b6c6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GPU info:\n",
            "Thu Jul  7 13:15:46 2022       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 460.32.03    Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   40C    P8     9W /  70W |      0MiB / 15109MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ],
      "source": [
        "print('GPU info:')\n",
        "!nvidia-smi"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "91ZJ0-RZIx6j"
      },
      "source": [
        "# Settings"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1644854038983
        },
        "id": "2mp2yFTEkp2u",
        "pycharm": {
          "name": "#%%\n"
        }
      },
      "outputs": [],
      "source": [
        "tf.random.set_seed(0)\n",
        "random.seed(0)\n",
        "# tf.keras.backend.set_floatx('float16')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1644859230857
        },
        "id": "FqDAqgl5UV58",
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": [
        "device: str\n",
        "if 'google.colab' in sys.modules:\n",
        "    device = 'colab'\n",
        "else:\n",
        "    device = 'locally'\n",
        "curr_folder = os.getcwd()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Define a strategy - Accelerator optimization "
      ],
      "metadata": {
        "id": "QlubPo7LRyNm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%capture\n",
        "# disable printing\n",
        "try:\n",
        "    resolver = tf.distribute.cluster_resolver.TPUClusterResolver();\n",
        "    tf.config.experimental_connect_to_cluster(resolver);\n",
        "    tf.tpu.experimental.initialize_tpu_system(resolver);\n",
        "    strategy = tf.distribute.TPUStrategy(resolver);\n",
        "    using_tpu: bool = True;\n",
        "except ValueError:\n",
        "    print(\"You must connect to a TPU in order to train a model. The models dont fit in a colab GPU\")\n",
        "    exit()"
      ],
      "metadata": {
        "id": "s0yqg12zqSt9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yVR1oJRD0NtO"
      },
      "source": [
        "# Data loading"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "gather": {
          "logged": 1644857858611
        },
        "id": "pn1UfAXQwlQX",
        "outputId": "af20cbcb-3d71-4d4b-be9a-5850b9f9741c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /drive; to attempt to forcibly remount, call drive.mount(\"/drive\", force_remount=True).\n",
            "(30279, 2)\n"
          ]
        }
      ],
      "source": [
        "if device == 'colab':  # If notebook is ran on colab\n",
        "    from google.colab import drive\n",
        "    drive.mount('/drive')\n",
        "    df: pd.DataFrame = pd.read_csv('/drive/MyDrive/final_project/wikipedia_articles.csv')\n",
        "else:  # If notebook is ran on my laptop\n",
        "    df: pd.DataFrame = pd.read_csv('wiki_data/articles.csv')\n",
        "print(df.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IW43lG6iUV6G",
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "outputId": "3fad9123-c6f0-4cf6-f625-6d22d0241bda"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "There are 30279 data points\n",
            "The length of the longest text IN CHARACTERS is: 141803\n",
            "The length of the shortest text IN CHARACTERS is: 816\n"
          ]
        }
      ],
      "source": [
        "df: pd.Series = df['text']\n",
        "data_list: List[str] = df.to_list()\n",
        "DATA_SIZE = len(data_list)\n",
        "print(f\"There are {DATA_SIZE} data points\")\n",
        "string_lengths: List[int] = [len(data_point) for data_point in data_list]\n",
        "max_string_len = max(string_lengths)\n",
        "print(f\"The length of the longest text IN CHARACTERS is: {max_string_len}\")\n",
        "min_string_len = min(string_lengths)\n",
        "print(f\"The length of the shortest text IN CHARACTERS is: {min_string_len}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "id": "87Putqz6kp20"
      },
      "source": [
        "## Creating the vocabulary"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KBhC3SPyMi9n"
      },
      "outputs": [],
      "source": [
        "# %%time\n",
        "bert_tokenizer_params: dict = dict(lower_case=True)\n",
        "VOCAB_SIZE: int = 8192  # Always the same for all models\n",
        "\n",
        "if device == 'colab':  # If notebook is ran on colab\n",
        "    path = '/drive/MyDrive/final_project/vocab.txt'\n",
        "else:  # If notebook is ran on my laptop\n",
        "    path = 'C:/yoni/final_project/model/vocab.txt'\n",
        "\n",
        "\n",
        "reserved_tokens: List[str] = [\"[PAD]\", \"[UNK]\", \"[START]\", \"[END]\", \"[MASK]\"]\n",
        "\n",
        "if os.path.exists(path):\n",
        "    with open(path, 'r') as f:\n",
        "        vocab: List[str] = f.read().split()\n",
        "else:\n",
        "    bert_vocab_args: dict = dict(\n",
        "        # The target vocabulary size\n",
        "        vocab_size = VOCAB_SIZE,\n",
        "        # Reserved tokens that must be included in the vocabulary\n",
        "        reserved_tokens=reserved_tokens,\n",
        "        # Arguments for `tf_text.BertTokenizer`\n",
        "        bert_tokenizer_params=bert_tokenizer_params,\n",
        "        # Arguments for `wordpiece_vocab.wordpiece_tokenizer_learner_lib.learn`\n",
        "        learn_params={},\n",
        "    )\n",
        "    tensor_list: list = [tf.convert_to_tensor(data_point) for data_point in data_list]\n",
        "    data_set: tf.data.Dataset = tf.data.Dataset.from_tensor_slices(tensor_list)\n",
        "    # I already ran this code and saved the file to C:/yoni/final_project/model/vocab.txt\n",
        "    vocab: List[str] = tf_text.bert_vocab_from_dataset.bert_vocab_from_dataset(\n",
        "        data_set,\n",
        "        **bert_vocab_args,)\n",
        "    with open('C:/yoni/final_project/model/vocab.txt', 'w') as f:\n",
        "        for token in vocab:\n",
        "            f.write(token + ' ')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4IZ5uxlJEoi3",
        "outputId": "a6886ce0-ea09-47e8-8ad6-3cc9e0bb8d25"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "the type of the items in vocab: <class 'str'>\n",
            "the first 15 items in vocab: ['[PAD]', '[UNK]', '[START]', '[END]', '[MASK]', \"'\", ',', '.', '0', '1', '2', '3', '4', '5', '6']\n",
            " the length of vocab: 7882\n"
          ]
        }
      ],
      "source": [
        "print(f\"the type of the items in vocab: {type(vocab[0])}\")\n",
        "print(f\"the first 15 items in vocab: {vocab[:15]}\")\n",
        "print(f\" the length of vocab: {len(vocab)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hndA44nhFw6I",
        "outputId": "9d396370-3326-4700-8a31-8fc4fd4a8125"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " the type of the items in tensor_vocab is: <class 'tensorflow.python.framework.ops.EagerTensor'>\n",
            " the data type of the tensors in tensor_vocab is: <dtype: 'string'>\n"
          ]
        }
      ],
      "source": [
        "tensor_vocab: List[tf.Tensor] = [tf.convert_to_tensor(token_key, dtype=tf.string) for token_key in vocab]  # dtype = tf.String\n",
        "print(f\" the type of the items in tensor_vocab is: {type(tensor_vocab[0])}\")\n",
        "print(f\" the data type of the tensors in tensor_vocab is: {tensor_vocab[0].dtype}\")\n",
        "vocab_size = len(vocab)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "id": "lD6QCFLAkp2_"
      },
      "source": [
        "## Creating the tokenizer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HihwIsrKD7C9"
      },
      "outputs": [],
      "source": [
        "lookup_table = tf.lookup.StaticVocabularyTable(\n",
        "    tf.lookup.KeyValueTensorInitializer(\n",
        "        keys=tensor_vocab,\n",
        "        key_dtype=tf.string,\n",
        "        values=tf.range(tf.size(vocab, out_type=tf.int64), dtype=tf.int64),\n",
        "        value_dtype=tf.int64),\n",
        "    num_oov_buckets=1\n",
        ")\n",
        "tokenizer = tf_text.BertTokenizer(lookup_table, **bert_tokenizer_params)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "id": "A73Lbgg6kp3R"
      },
      "source": [
        "## Tokenizing the data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mLxV5l562-x2"
      },
      "outputs": [],
      "source": [
        "# START: int = tf.argmax(tf.constant(reserved_tokens) == \"[START]\")  # The value of the start token\n",
        "# END: int = tf.argmax(tf.constant(reserved_tokens) == \"[END]\")  # The value of the end token\n",
        "# starts = tf.cast(tf.Variable([START]), dtype = tf.int32)  # Tensor of shape [1] and dtype int\n",
        "# ends = tf.cast(tf.Variable([END]), dtype = tf.int32)  # Tensor of shape [1] and dtype int\n",
        "starts = tf.constant([2], dtype=tf.int32)\n",
        "ends = tf.constant([3], dtype=tf.int32)\n",
        "pad_int: int = int(tf.argmax(tf.constant(reserved_tokens) == \"[PAD]\"))\n",
        "pad_ten: tf.TensorSpec(dtype=tf.int32, shape=()) = tf.constant([pad_int], dtype=tf.int32)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4gPxVc7tkp3X",
        "pycharm": {
          "name": "#%%\n"
        }
      },
      "outputs": [],
      "source": [
        "def tokenize_string(text: str) -> tf.Tensor:\n",
        "    \"\"\"Converts string to tensor\"\"\"\n",
        "    ragged: tf.RaggedTensor = tokenizer.tokenize(text)[0, :]\n",
        "    eager: tf.Tensor = ragged.to_tensor(default_value=0, shape=[None, 1])  # 0 is the value of the padding token\n",
        "    sqeezed: tf.Tensor = tf.squeeze(eager, axis=1)\n",
        "    typed: tf.Tensor = tf.cast(sqeezed, tf.int32)\n",
        "    edited: tf.Tensor = tf.concat([starts, typed, ends], axis=0)\n",
        "    return edited"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UzHmzHSukp3a",
        "pycharm": {
          "name": "#%%\n"
        }
      },
      "outputs": [],
      "source": [
        "tokenized_data: List[tf.Tensor] = [tokenize_string(data_point) for data_point in data_list] \n",
        "\n",
        "# tqdm is a progress bar"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CNEdwxWFkp3d",
        "outputId": "2813d6de-6975-4cdb-8421-39479c7f02fb",
        "pycharm": {
          "name": "#%%\n"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "30279\n",
            "(670,)\n",
            "tf.Tensor([   2 1011 7670   57   18 6423  617   33   61   44], shape=(10,), dtype=int32)\n"
          ]
        }
      ],
      "source": [
        "print(len(tokenized_data))\n",
        "print(tokenized_data[0].shape)\n",
        "print(tokenized_data[0][:10])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D77Pm-iGkp3j",
        "outputId": "d37332d0-2151-45f6-de7c-48578f4e35e0",
        "pycharm": {
          "name": "#%%\n"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "25315\n",
            "178\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 360x360 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "lengths_tokenized: List[int] = [text.shape[0] for text in tokenized_data]\n",
        "print(max(lengths_tokenized))\n",
        "print(min(lengths_tokenized))\n",
        "sns.displot(lengths_tokenized);"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "id": "EtjxgLWMkp3l"
      },
      "source": [
        "### chunk too long texts"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MubdHBEMkJNC"
      },
      "outputs": [],
      "source": [
        "max_seq_len: int = 256\n",
        "def chunk_tensor(tensor: tf.Tensor, max_len: int = max_seq_len) -> List[tf.Tensor]:\n",
        "    \"\"\"Splits 1d tensor to chunks (1d tensors) of maximum size: max_len\"\"\"\n",
        "    return [tensor[i*max_len:(i+1)*max_len] for i in range(tensor.shape[0] // max_len)]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9DgU2Or2kp3m",
        "outputId": "596803b2-a306-4ef7-92c0-a497ecc507e3",
        "pycharm": {
          "name": "#%%\n"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "336056\n",
            "(256,)\n"
          ]
        }
      ],
      "source": [
        "chunked_data: List[tf.Tensor] = []\n",
        "for tensor in tokenized_data:\n",
        "    chunks = chunk_tensor(tensor, max_seq_len)\n",
        "    for chunk in chunks:\n",
        "        chunked_data.append(chunk)\n",
        "DATA_SIZE: int = len(chunked_data)\n",
        "print(DATA_SIZE)\n",
        "print(chunked_data[0].shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R8Z2_P2Lnke8"
      },
      "source": [
        "## Padding"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XUOVoGBfkp3p",
        "pycharm": {
          "name": "#%%\n"
        }
      },
      "outputs": [],
      "source": [
        "def pad(tensor: tf.Tensor, pad_int: int) -> tf.Tensor:\n",
        "    \"\"\"Pads the tensor to the length of the longest text in the data set\"\"\"\n",
        "    padded: tf.Tensor = tf.pad(tensor=tensor, paddings=[[pad_int, max_seq_len - tensor.shape[0]]], mode='CONSTANT', constant_values=0)\n",
        "    # 0 is the padding token\n",
        "    return padded"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nRa9_ryHkp3p",
        "pycharm": {
          "name": "#%%\n"
        }
      },
      "outputs": [],
      "source": [
        "padded_data: List[tf.Tensor] = [pad(text, pad_int) for text in chunked_data]\n",
        "chunked_data.sort(key = lambda t: t.shape[0])  # sorting so that every batch will have similar sized texts"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "id": "gbnub0UZkp3s"
      },
      "source": [
        "## Train test val split"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size: int = 128 if using_tpu else 32\n",
        "\n",
        "def list_to_dataset(tokenized_list: List[tf.Tensor]) -> tf.data.Dataset:\n",
        "    \"\"\"Converts a list of tokenized texts after all preprocessing to a tf.data.Dataset\"\"\"\n",
        "    dataset: tf.data.Dataset = tf.data.Dataset.from_tensor_slices(tokenized_list)\n",
        "    batched: tf.data.Dataset = dataset.batch(batch_size)\n",
        "    return batched\n",
        "\n",
        "batched_data_ten = list_to_dataset(padded_data)\n",
        "batched_data_list = list(batched_data_ten)\n",
        "random.shuffle(batched_data_list)\n",
        "if batched_data_list[-1].shape[0] != batch_size:\n",
        "    batched_data_list = batched_data_list[:-1]\n",
        "data_size = len(batched_data_list)\n",
        "train_size: int = int(data_size * 0.8) \n",
        "val_test_size: int = int(data_size * 0.1)  # Both validation and test get 10% of the data\n",
        "list_train_set: List[tf.Tensor] = batched_data_list[:train_size]\n",
        "list_val_set: List[tf.Tensor] = batched_data_list[train_size:(train_size + val_test_size)]\n",
        "list_test_set: List[tf.Tensor] = batched_data_list[(train_size + val_test_size)]"
      ],
      "metadata": {
        "id": "pTW48b8Qr6sv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HzS72rcIvL0N"
      },
      "source": [
        "## Clear memory"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VlkhQigKvOQT"
      },
      "outputs": [],
      "source": [
        "del batched_data_list, train_size, val_test_size, data_size\n",
        "del padded_data, chunked_data, tokenized_data, data_list, df, lengths_tokenized\n",
        "del lookup_table, reserved_tokens\n",
        "del bert_tokenizer_params, ends, starts, vocab, tensor_vocab\n",
        "del chunk, chunks"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5vBLynXu0QI1"
      },
      "source": [
        "# Model\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A9qUAZ00xiVd"
      },
      "source": [
        "## Positional encoding"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "id": "_V1b_16-kp3v"
      },
      "source": [
        "The formula for calculating the positional encoding is as follows:\n",
        "\n",
        "$${PE_{(pos, 2i)} = \\sin(pos / 10000^{2i / d_{model}})} $$\n",
        "$${PE_{(pos, 2i+1)} = \\cos(pos / 10000^{2i / d_{model}})} $$\n",
        "\n",
        "where $d_{model}$ is the model dimension, $pos$ is the position and $i$ is the index of the embedding.\n",
        "this is taken from the paper: attention is all you need."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Wx4hze4k0yls"
      },
      "outputs": [],
      "source": [
        "def create_positional_encoding(max_len: int, d_model: int) -> tf.Tensor:\n",
        "    \"\"\"Returns the positional encoding for a given a maximal sequence length and model dimension.\n",
        "    inputs: max_len: int, d_model: int\n",
        "    returns: tf.Tensor of shape (1, max_len, d_model) and dtype tf.keras.backend.floatx()\n",
        "    The 1 is for the batch dimension, the place in the batch dimension does not matter\"\"\"\n",
        "\n",
        "    def get_angles(positions: np.ndarray, timestamps: np.ndarray, d_model: int) -> np.ndarray:\n",
        "        \"\"\"Returns the angle in radians for given positions, timestamps and the dimension of the model\n",
        "        input: positions: np.ndarray of shape (max_len, 1), timestamps: np.ndarray of shape (1, d_model), d_model: int\n",
        "        output: np.ndarray of shape (max_len, d_model)\"\"\"\n",
        "        if tf.keras.backend.floatx() == \"float32\":\n",
        "            angle_rates = 1 / np.power(10000, ((2 * (timestamps//2)) / np.float32(d_model)))\n",
        "        else:\n",
        "            angle_rates = 1 / np.power(10000, ((2 * (timestamps//2)) / np.float16(d_model)))\n",
        "\n",
        "        return positions * angle_rates\n",
        "    \n",
        "    angle_rads = get_angles(np.arange(max_len)[:, np.newaxis],\n",
        "                            np.arange(d_model)[np.newaxis, :],\n",
        "                            d_model)  # (max_len, d_model)\n",
        "\n",
        "    # apply sin to even indices in the array; 2i for i in range(d_model // 2)\n",
        "    angle_rads[:, 0::2] = np.sin(angle_rads[:, 0::2])  # (max_len, d_model)\n",
        "\n",
        "    # apply cos to odd indices in the array; 2i+1\n",
        "    angle_rads[:, 1::2] = np.cos(angle_rads[:, 1::2])  # (max_len, d_model)\n",
        "\n",
        "    pos_encode = angle_rads[np.newaxis, ...]  # (1, max_len, d_model)\n",
        "\n",
        "    return tf.cast(pos_encode, dtype=tf.keras.backend.floatx())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6ib5F3hnxrE9"
      },
      "source": [
        "## Masking"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3TXw70UlzcVi"
      },
      "source": [
        "Mask all the pad tokens in the batch of sequence. It ensures that the model does not treat padding as the input. The mask indicates where pad value 0 is present: it outputs a 1 at those locations, and a 0 otherwise."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4w68l26GzrqG"
      },
      "source": [
        "The look-ahead mask is used to mask the future tokens in a sequence. In other words, the mask indicates which entries should not be used.\n",
        "\n",
        "This means that to predict the third token, only the first and second token will be used. Similarly to predict the fourth token, only the first, second and the third tokens will be used and so on."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BQkjgUVVckzJ"
      },
      "outputs": [],
      "source": [
        "def create_masks(inp: tf.Tensor, tar: tf.Tensor, pad_ten: tf.Tensor) -> Tuple[tf.Tensor, tf.Tensor]:\n",
        "        \"\"\"Creates all the masks needed for the model\n",
        "        input: inp: tf.Tensor of shape (batch_size, seq_len), tar: tf.Tensor of shape (batch_size, set_size)\n",
        "        Returns: tuple of (padding_mask, look_ahead_mask)\n",
        "        padding_mask, look_ahead_mask: tf.Tensor of shape (batch_size, 1, 1, seq_len)\"\"\"\n",
        "        \n",
        "        def create_padding_mask(seq: tf.Tensor) -> tf.Tensor:\n",
        "                \"\"\"Returns a padding mask for the given sequence.\n",
        "                input: seq: tf.Tensor of shape (batch_size, seq_len)\n",
        "                Returns: tf.Tensor of shape (batch_size, 1, 1, seq_len)\"\"\"\n",
        "                seq = tf.cast(tf.math.equal(seq, pad_ten), tf.keras.backend.floatx())  \n",
        "                # For every item in the sequence, 1 if it is a padding token, 0 if it is not \n",
        "\n",
        "                # add extra dimensions to add the padding\n",
        "                \n",
        "                return seq[:, tf.newaxis, tf.newaxis, :]  # (batch_size, 1, 1, seq_len)\n",
        "        \n",
        "        # Encoder padding mask\n",
        "        padding_mask: tf.Tensor = create_padding_mask(inp)  # (batch_size, 1, 1, seq_len)\n",
        "\n",
        "        # Used in the 1st attention block in the decoder.\n",
        "        # It is used to pad and mask future tokens in the input received by\n",
        "        # the decoder.\n",
        "        set_size: int = tar.shape[1]\n",
        "\n",
        "        def create_look_ahead_mask(set_size: int) -> tf.Tensor:\n",
        "                mask = 1 - tf.linalg.band_part(tf.ones((set_size, set_size)), -1, 0)\n",
        "                mask = tf.cast(mask, dtype=tf.keras.backend.floatx())\n",
        "                return mask  # (seq_len, seq_len)\n",
        "\n",
        "        look_ahead_mask = create_look_ahead_mask(set_size)  # (seq_len, seq_len)\n",
        "        dec_target_padding_mask = create_padding_mask(tar)  # (batch_size, 1, 1, seq_len)\n",
        "        look_ahead_mask = tf.maximum(dec_target_padding_mask, look_ahead_mask) # (batch_size, 1, 1, seq_len)\n",
        "\n",
        "        return padding_mask, look_ahead_mask"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9KHKaxz3xumc"
      },
      "source": [
        "## Layers and blocks"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gRXst-o2NjXL"
      },
      "outputs": [],
      "source": [
        "class ScaledDotProductAttention(tf.keras.layers.Layer):\n",
        "    def __init__(self, d_model: int, **kwargs):\n",
        "        super().__init__(**kwargs)\n",
        "        self.scale: tf.TensorSpec(shape=(), dtype=tf.keras.backend.floatx())\n",
        "        # scale = 1 / sqrt(d_model)\n",
        "        self.scale = tf.math.pow(tf.cast(d_model, tf.keras.backend.floatx()), -0.5)\n",
        "        self.softmax = tf.keras.layers.Softmax(axis=-1)\n",
        "\n",
        "    def call(self, q: tf.Tensor, k: tf.Tensor, v: tf.Tensor, mask: Optional[tf.Tensor] = None) -> tf.Tensor:\n",
        "        \"\"\"Scaled Dot-Product Attention\n",
        "        input: \n",
        "        q: tf.Tensor of shape (batch_size, seq_len, d_model), \n",
        "        k: tf.Tensor of shape (batch_size, seq_len, d_model), \n",
        "        v: tf.Tensor of shape (batch_size, seq_len, d_model), \n",
        "        mask: Optional[tf.Tensor] of shape (batch_size, 1, 1, seq_len)\n",
        "        output: tf.Tensor of shape (batch_size, seq_len, d_model)\"\"\"\n",
        "        matmul_qk: tf.Tensor = tf.matmul(q, k, transpose_b=True)  # (..., seq_len_q, seq_len_k)\n",
        "\n",
        "        # Scaled Dot-Product Attention\n",
        "        scaled_attention_logits: tf.Tensor = matmul_qk * self.scale  # (..., seq_len_q, seq_len_k)\n",
        "        # matmul_qk / sqrt(d_model)\n",
        "\n",
        "        # Masking\n",
        "        if mask is not None:\n",
        "            # noinspection PyTypeChecker\n",
        "            if tf.keras.backend.floatx() == 'float16':\n",
        "                # tf.float16.min is minus infinity\n",
        "                scaled_attention_logits += (mask * tf.float16.min)  # changed from -1e9 to prevent nan's\n",
        "            else:\n",
        "                scaled_attention_logits += (mask * -1e9) \n",
        "\n",
        "        # Normalize\n",
        "        attention_weights = self.softmax(scaled_attention_logits)\n",
        "        # (..., seq_len_q, seq_len_k)\n",
        "\n",
        "        # Output\n",
        "        output = tf.matmul(attention_weights, v)\n",
        "\n",
        "        return output"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_0I9SZI0kp31",
        "pycharm": {
          "name": "#%%\n"
        }
      },
      "outputs": [],
      "source": [
        "class MyMultiHeadAttention(tf.keras.layers.Layer):\n",
        "    \"\"\"U can use the built-in tf.keras.layers.multihead_attention but is caused a bug for me\"\"\"\n",
        "    def __init__(self, num_heads: int, d_model: int, **kwargs):\n",
        "        super().__init__(**kwargs)\n",
        "        if d_model % num_heads != 0:\n",
        "            raise ValueError(f\"d_model ({d_model}) must be divisible by num_heads ({num_heads})\")\n",
        "        self.num_heads = num_heads\n",
        "        self.d_model = d_model\n",
        "        self.depth = d_model // self.num_heads\n",
        "\n",
        "        self.wq = tf.keras.layers.Dense(d_model)\n",
        "        self.wk = tf.keras.layers.Dense(d_model)\n",
        "        self.wv = tf.keras.layers.Dense(d_model)\n",
        "\n",
        "        self.dense = tf.keras.layers.Dense(d_model)\n",
        "        self.sdpa = ScaledDotProductAttention(d_model)\n",
        "\n",
        "    def split_heads(self, x: tf.Tensor, batch_size: int) -> tf.Tensor:\n",
        "        \"\"\"Split the last dimension into (num_heads, depth).\n",
        "        Transpose the result such that the shape is (batch_size, num_heads, seq_len, depth)\n",
        "        \"\"\"\n",
        "        x = tf.reshape(x, (batch_size, -1, self.num_heads, self.depth))\n",
        "        return tf.transpose(x, perm=[0, 2, 1, 3])\n",
        "\n",
        "    def call(self, v_k: tf.Tensor, q: tf.Tensor, mask: tf.Tensor) -> tf.Tensor:\n",
        "        \"\"\"inputs:\n",
        "        v_k: tf.Tensor of shape (batch_size, seq_len, d_model) in self attention keys and values are the same\n",
        "        q: tf.Tensor of shape (batch_size, seq_len, d_model)\n",
        "        mask: Optional[tf.Tensor] of shape (batch_size, seq_len)\"\"\"\n",
        "        batch_size = tf.shape(q)[0]\n",
        "\n",
        "        q: tf.Tensor = self.wq(q)  # (batch_size, seq_len, d_model)\n",
        "        k: tf.Tensor = self.wk(v_k)  # (batch_size, seq_len, d_model)\n",
        "        v: tf.Tensor = self.wv(v_k)  # (batch_size, seq_len, d_model)\n",
        "\n",
        "        q: tf.Tensor = self.split_heads(q, batch_size)  # (batch_size, num_heads, seq_len_q, depth)\n",
        "        k: tf.Tensor = self.split_heads(k, batch_size)  # (batch_size, num_heads, seq_len_k, depth)\n",
        "        v: tf.Tensor = self.split_heads(v, batch_size)  # (batch_size, num_heads, seq_len_v, depth)\n",
        "\n",
        "        # scaled_attention.shape should be (batch_size, num_heads, seq_len_q, depth)\n",
        "        scaled_attention = self.sdpa(q, k, v, mask)\n",
        "\n",
        "        scaled_attention = tf.transpose(scaled_attention, perm=[0, 2, 1, 3]) \n",
        "         # (batch_size, seq_len_q, num_heads, depth)\n",
        "\n",
        "        concat_attention = tf.reshape(scaled_attention, (batch_size, -1, self.d_model))\n",
        "          # (batch_size, seq_len_q, d_model)\n",
        "\n",
        "        output = self.dense(concat_attention)  # (batch_size, seq_len_q, d_model)\n",
        "\n",
        "        return output"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QOVbpMxtNjXQ"
      },
      "outputs": [],
      "source": [
        "class PointWiseFeedForwardNetwork(tf.keras.layers.Layer):\n",
        "    def __init__(self, d_model: int, dff: int, **kwargs): \n",
        "        super().__init__(**kwargs)\n",
        "        self.layer1 = tf.keras.layers.Dense(dff, activation='relu')  # (batch_size, seq_len, dff)\n",
        "        self.layer2 = tf.keras.layers.Dense(d_model)  # (batch_size, seq_len, d_model)\n",
        "    \n",
        "    def call(self, x: tf.Tensor) -> tf.Tensor:\n",
        "        \"\"\"Gets tensor of shape (batch_size, seq_len, d_model) and dtype tf.keras.beckend.floatx()\n",
        "        Returns tensor of shape (batch_size, seq_len, d_model) and dtype tf.keras.beckend.floatx()\"\"\"\n",
        "        x = self.layer1(x)\n",
        "        x = self.layer2(x)\n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8mEP3-Jx2n39"
      },
      "outputs": [],
      "source": [
        "class EncoderBlock(tf.keras.layers.Layer):\n",
        "    def __init__(self, d_model: int, num_heads: int, dff: int, drop_out_rate: float, **kwargs):\n",
        "        super().__init__(**kwargs)\n",
        "\n",
        "        self.mha = MyMultiHeadAttention(num_heads = num_heads, d_model = d_model)\n",
        "        self.ffn = PointWiseFeedForwardNetwork(d_model, dff)\n",
        "\n",
        "        self.layer_norm = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
        "\n",
        "        self.dropout = tf.keras.layers.Dropout(drop_out_rate)\n",
        "\n",
        "    def call(self, x: tf.Tensor, training: bool, mask: tf.Tensor) -> tf.Tensor:\n",
        "        \n",
        "        attn_output = self.mha(x, x, mask)  # (batch_size, input_seq_len, d_model)\n",
        "        attn_output = self.dropout(attn_output, training=training)  # (batch_size, input_seq_len, d_model)\n",
        "        # out1 = self.layer_norm(x + attn_output)  # (batch_size, input_seq_len, d_model)\n",
        "        # might be data leak\n",
        "        out1 = self.layer_norm(attn_output)  # (batch_size, input_seq_len, d_model)\n",
        "        \n",
        "        ffn_output = self.ffn(out1)  # (batch_size, input_seq_len, d_model)\n",
        "        ffn_output = self.dropout(ffn_output, training=training)  # (batch_size, input_seq_len, d_model)\n",
        "        out2 = self.layer_norm(out1 + ffn_output)  # (batch_size, input_seq_len, d_model)\n",
        "\n",
        "        return out2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xJWFrv0g281G"
      },
      "outputs": [],
      "source": [
        "class DecoderBlock(tf.keras.layers.Layer):\n",
        "    def __init__(self, d_model: int, num_heads: int, dff: int, rate: float, **kwargs):\n",
        "        super().__init__(**kwargs)\n",
        "\n",
        "        self.mha = MyMultiHeadAttention(num_heads = num_heads, d_model = d_model)\n",
        "\n",
        "        self.ffn = PointWiseFeedForwardNetwork(d_model, dff)\n",
        "\n",
        "        self.layer_norm = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
        "\n",
        "        self.dropout = tf.keras.layers.Dropout(rate)\n",
        "\n",
        "    def call(self, x: tf.Tensor, enc_output: tf.Tensor, look_ahead_mask: tf.Tensor, padding_mask: tf.Tensor, training):\n",
        "        # enc_output.shape should be (batch_size, input_seq_len, d_model)\n",
        "\n",
        "        attn1 = self.mha(x, x, look_ahead_mask)  # (batch_size, set_size, d_model)\n",
        "        attn1 = self.dropout(attn1, training=training)  # (batch_size, set_size, d_model)\n",
        "        # out1 = self.layer_norm(attn1 + x)\n",
        "        # might be data leak\n",
        "        out1 = self.layer_norm(attn1)  # (batch_size, set_size, d_model)\n",
        "\n",
        "        attn2 = self.mha(enc_output, out1, padding_mask)  # (batch_size, set_size, d_model)\n",
        "        attn2 = self.dropout(attn2, training=training)  # (batch_size, set_size, d_model)\n",
        "        out2 = self.layer_norm(attn2 + out1)  # (batch_size, set_size, d_model)\n",
        "\n",
        "        ffn_output = self.ffn(out2)  # (batch_size, set_size, d_model)\n",
        "        ffn_output = self.dropout(ffn_output, training=training)\n",
        "        out3 = self.layer_norm(ffn_output + out2)  # (batch_size, set_size, d_model)\n",
        "\n",
        "        return out3 "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NdlS1kfM3k5d"
      },
      "outputs": [],
      "source": [
        "class Encoder(tf.keras.layers.Layer):\n",
        "    def __init__(self, pos_encoding: tf.Tensor, num_blocks: int, d_model: int, num_heads: int, dff: int, rate=0.1, **kwargs):\n",
        "        super().__init__(**kwargs)\n",
        "\n",
        "        self.d_model = d_model\n",
        "        self.num_blocks = num_blocks\n",
        "        self.pos_encoding = pos_encoding\n",
        "\n",
        "        self.enc_blocks = [EncoderBlock(d_model, num_heads, dff, rate) for _ in range(num_blocks)]\n",
        "        # the encoder \n",
        "        self.dropout = tf.keras.layers.Dropout(rate)\n",
        "        self.scale = tf.math.sqrt(tf.cast(self.d_model, tf.keras.backend.floatx()))\n",
        "\n",
        "    def call(self, x: tf.Tensor, training, mask: tf.Tensor) -> tf.Tensor:\n",
        "\n",
        "        seq_len = tf.shape(x)[1]\n",
        "\n",
        "        # adding position encoding.\n",
        "        # assert not tf.math.is_nan(x[0][0][0])\n",
        "        x *= self.scale\n",
        "        # assert not tf.math.is_nan(x[0][0][0])\n",
        "        \n",
        "        x += self.pos_encoding[:, :seq_len, :]  # (batch_size, input_seq_len, d_model)\n",
        "        # assert not tf.math.is_nan(x[0][0][0])\n",
        "        x = self.dropout(x, training=training)  # (batch_size, input_seq_len, d_model)\n",
        "        # assert not tf.math.is_nan(x[0][0][0])\n",
        "\n",
        "        for i in range(self.num_blocks):\n",
        "            x = self.enc_blocks[i](x, training, mask)  # (batch_size, input_seq_len, d_model)\n",
        "            # assert not tf.math.is_nan(x[0][0][0])\n",
        "\n",
        "        return x  # (batch_size, input_seq_len, d_model)  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QLE8js6O3p5-"
      },
      "outputs": [],
      "source": [
        "class Decoder(tf.keras.layers.Layer):\n",
        "    def __init__(self, pos_encoding, num_blocks: int, d_model: int, num_heads: int, dff: int,\n",
        "                 vocab_size: int, rate: float, **kwargs):\n",
        "        super().__init__(**kwargs)\n",
        "\n",
        "        self.scale = tf.math.sqrt(tf.cast(d_model, tf.keras.backend.floatx()))\n",
        "        self.num_blocks = num_blocks\n",
        "        self.pos_encoding = pos_encoding\n",
        "\n",
        "        self.embedding = tf.keras.layers.Embedding(vocab_size, d_model)\n",
        "        self.dec_layers = [DecoderBlock(d_model, num_heads, dff, rate) for _ in range(num_blocks)]\n",
        "        self.dropout = tf.keras.layers.Dropout(rate)\n",
        "\n",
        "    def call(self, tar: tf.Tensor, enc_output: tf.Tensor, training: bool,\n",
        "             look_ahead_mask: tf.Tensor, padding_mask: tf.Tensor) -> tf.Tensor:\n",
        "\n",
        "        seq_len = tf.shape(tar)[1]\n",
        "\n",
        "        x = self.embedding(tar)  # (batch_size, set_size, d_model)\n",
        "        x *= self.scale\n",
        "        x += self.pos_encoding[:, :seq_len, :]\n",
        "\n",
        "        x = self.dropout(x, training=training)\n",
        "\n",
        "        for i in range(self.num_blocks):\n",
        "            x = self.dec_layers[i](x=x, enc_output=enc_output, look_ahead_mask=look_ahead_mask, \n",
        "                                   padding_mask=padding_mask, training=training)\n",
        "\n",
        "        # x.shape should be (batch_size, set_size, d_model)\n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class EmbeddingTransposed(tf.keras.layers.Layer):\n",
        "    def __init__(self, tied_to: tf.keras.layers.Embedding = None, activation: Optional[str] = None, **kwargs):\n",
        "        super(EmbeddingTransposed, self).__init__(**kwargs)\n",
        "        self.tied_to = tied_to\n",
        "        self.activation = tf.keras.activations.get(activation)\n",
        "\n",
        "    def build(self, input_shape):\n",
        "        self.custom_weights = self.tied_to.weights[0]\n",
        "        self.built = True\n",
        "\n",
        "    def compute_output_shape(self, input_shape):\n",
        "        return input_shape[0], tf.keras.backend.int_shape(self.tied_to.weights[0])[0]\n",
        "\n",
        "    def call(self, inputs, mask=None):\n",
        "        output = tf.keras.backend.dot(inputs, tf.keras.backend.transpose(self.custom_weights))\n",
        "        if self.activation is not None:\n",
        "            output = self.activation(output)\n",
        "        return output\n",
        "\n",
        "    def get_config(self):\n",
        "        config = {\"activation\": tf.keras.activations.serialize(self.activation)}\n",
        "        base_config = super(EmbeddingTransposed, self).get_config()\n",
        "        return dict(list(base_config.items()) + list(config.items()))"
      ],
      "metadata": {
        "id": "6uaYfyRdEtBN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1-xe3K7LyD2l"
      },
      "source": [
        "## The full model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4NLhyE0T3tUs"
      },
      "outputs": [],
      "source": [
        "class SeTransformer(tf.keras.Model):\n",
        "    \"\"\"The base architecture of my models in this project.\"\"\"\n",
        "    def __init__(self, num_blocks: int, d_model: int, num_heads: int, dff: int,\n",
        "                 vocab_size: int, max_len: int, rate: float, pad_int: int, using_tpu: bool, **kwargs):\n",
        "        super().__init__(**kwargs)  # calls tf.keras.Model's __init__ method\n",
        "        self.pad_int = pad_int\n",
        "        self.vocab_size = vocab_size\n",
        "        pos_encoding = create_positional_encoding(max_len, d_model)\n",
        "        self.d_model = d_model\n",
        "\n",
        "        self.encoder = Encoder(pos_encoding, num_blocks, d_model, num_heads, dff, rate)\n",
        "        self.decoder = Decoder(pos_encoding, num_blocks, d_model, num_heads, dff, vocab_size, rate)\n",
        "\n",
        "        self.embedding = tf.keras.layers.Embedding(input_dim=vocab_size, output_dim=d_model)\n",
        "        self.emb_trans = EmbeddingTransposed(self.embedding, \"softmax\")\n",
        "        # self.dense = tf.keras.layers.Dense(vocab_size, activation=\"softmax\")\n",
        "\n",
        "\n",
        "    def count_params(self) -> int:\n",
        "        \"\"\"counts trainable parameters\n",
        "        Raises an error if caleed before building the model\"\"\"\n",
        "        param_count: int = self.encoder.count_params() + self.decoder.count_params() + self.embedding.count_params() + self.emb_trans.count_params()\n",
        "        assert isinstance(param_count, int)\n",
        "        return param_count\n",
        "\n",
        "\n",
        "    def call(self, inputs: list, training: bool) -> tf.Tensor:\n",
        "        inp, tar = inputs\n",
        "        # inp.shape should be (batch_size, max_seq_len)\n",
        "        # tar.shape should be (batch_size, set_size)\n",
        "        x = self.embedding(inp)  # (batch_size, max_seq_len, d_model)\n",
        "        # for d0 in range(x.shape[0]):\n",
        "        #     for d1 in range(x.shape[1]):\n",
        "        #         for d2 in range(x.shape[2]):\n",
        "        #             assert not tf.math.is_nan(x[d0][d1][d2])\n",
        "        # if len(x.shape) == 3:\n",
        "        #     assert not tf.math.is_nan(x[0][0][0])\n",
        "        # elif len(x.shape) == 2:\n",
        "        #     assert not tf.math.is_nan(x[0][0])\n",
        "        # else: raise ValueError('embedding output should by 3 dim tensor')\n",
        "        padding_mask, look_ahead_mask = create_masks(inp, tar, self.pad_int)\n",
        "        \n",
        "        enc_output = self.encoder(x, training, padding_mask)  # (batch_size, max_seq_len, d_model)\n",
        "        # assert not tf.math.is_nan(enc_output[0][0][0])\n",
        "\n",
        "        # dec_output.shape should be (batch_size, set_size, d_model)\n",
        "        dec_output = self.decoder(tar, enc_output, training, look_ahead_mask, padding_mask)\n",
        "        # assert not tf.math.is_nan(dec_output[0][0][0])\n",
        "\n",
        "        final_output = self.emb_trans(dec_output)\n",
        "        # assert not tf.math.is_nan(final_output[0][0][0])\n",
        "        return final_output"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3WZ41cb-1B_f",
        "outputId": "36a9e5ad-0737-4a6c-ef71-b85b208ca4e7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING: model output depends on the target\n",
            "tf.Tensor(\n",
            "[[[1.15601404e-04 1.00934602e-04 1.55265472e-04 ... 1.62815239e-04\n",
            "   1.59162548e-04 1.23081874e-04]\n",
            "  [1.09918677e-04 1.05700725e-04 1.45990314e-04 ... 1.52201581e-04\n",
            "   1.42956109e-04 1.32665285e-04]\n",
            "  [9.97192910e-05 1.18472752e-04 1.44033955e-04 ... 1.62413868e-04\n",
            "   1.32923684e-04 1.48421663e-04]\n",
            "  ...\n",
            "  [9.47656445e-05 1.21456826e-04 1.57714909e-04 ... 1.65316000e-04\n",
            "   1.45888436e-04 1.40580785e-04]\n",
            "  [1.05273932e-04 1.18380987e-04 1.60773139e-04 ... 1.61111850e-04\n",
            "   1.36885632e-04 1.36959861e-04]\n",
            "  [1.11600384e-04 1.10392466e-04 1.62879311e-04 ... 1.62439799e-04\n",
            "   1.35497758e-04 1.25011953e-04]]], shape=(1, 8, 7000), dtype=float32)\n",
            "tf.Tensor(\n",
            "[[[9.09473965e-05 1.16539813e-04 1.35742303e-04 ... 1.65404737e-04\n",
            "   1.38030431e-04 1.50942520e-04]\n",
            "  [9.98887626e-05 1.10046654e-04 1.33460926e-04 ... 1.60958094e-04\n",
            "   1.41049357e-04 1.48143139e-04]\n",
            "  [1.04687300e-04 1.10940069e-04 1.21875091e-04 ... 1.57932300e-04\n",
            "   1.37086812e-04 1.60027557e-04]\n",
            "  ...\n",
            "  [1.00436497e-04 1.11514993e-04 1.27791282e-04 ... 1.52880966e-04\n",
            "   1.36653412e-04 1.51433967e-04]\n",
            "  [1.08299093e-04 1.04470484e-04 1.28017928e-04 ... 1.57816510e-04\n",
            "   1.39764961e-04 1.41430923e-04]\n",
            "  [1.10702917e-04 9.81523990e-05 1.44970807e-04 ... 1.57103830e-04\n",
            "   1.46093138e-04 1.31863664e-04]]], shape=(1, 8, 7000), dtype=float32)\n",
            "(1, 8, 7000)\n",
            "(1, 8, 7000)\n"
          ]
        }
      ],
      "source": [
        "sample_transformer = SeTransformer(\n",
        "    num_blocks=2, d_model=32, num_heads=4, dff=128,\n",
        "    vocab_size=7000,\n",
        "    max_len=1200, pad_int=0, rate=0.1, using_tpu=False)\n",
        "\n",
        "temp_input = tf.random.uniform((1, 200), dtype=tf.int32, minval=5, maxval=6999)\n",
        "temp_target = tf.random.uniform((1, 8), dtype=tf.int32, minval=5, maxval=6999)\n",
        "temp_target2 = temp_target + 3\n",
        "\n",
        "train_out = sample_transformer([temp_input, temp_target], training=True)\n",
        "train_out2 = sample_transformer([temp_input, temp_target2], training=True)\n",
        "\n",
        "try:\n",
        "    tf.debugging.assert_equal(train_out, train_out2)\n",
        "except tf.errors.InvalidArgumentError:\n",
        "    print(\"WARNING: model output depends on the target\")\n",
        "\n",
        "non_train_out = sample_transformer([temp_input, temp_target], training=False)\n",
        "print(f\"The attribuites of the model are: {dir(sample_transformer)}\")\n",
        "\n",
        "del sample_transformer, train_out, non_train_out, temp_target2, train_out2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "id": "hFxiRfCekp38"
      },
      "source": [
        "# Training the model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "id": "B5rtigmHckyv"
      },
      "source": [
        "## Hyper-Parameters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bWmh89nVckyw",
        "pycharm": {
          "name": "#%%\n"
        }
      },
      "outputs": [],
      "source": [
        "set_size: int = 2\n",
        "learning_rate: float = 0.01\n",
        "\n",
        "num_sets: int = (max_seq_len // set_size) - 1 # Because we dont predict the first set\n",
        "# number of sets in each sequence\n",
        "\n",
        "num_blocks: int = 8\n",
        "d_model: int = 256\n",
        "dff: int = 512\n",
        "num_heads: int = 16\n",
        "dropout_rate: float = 0.1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O783T1xMckzR"
      },
      "source": [
        "## Create the model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-uAxXGBtkp4A",
        "pycharm": {
          "name": "#%%\n"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "898c89bb-118b-4c84-e398-4171a2904b42"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The model has 4,084,480 trainable parameters\n"
          ]
        }
      ],
      "source": [
        "with strategy.scope():\n",
        "    model = SeTransformer(\n",
        "        num_blocks=num_blocks,\n",
        "        d_model=d_model,\n",
        "        num_heads=num_heads,\n",
        "        dff=dff,\n",
        "        vocab_size=vocab_size,\n",
        "        max_len=max_seq_len,\n",
        "        rate=dropout_rate,\n",
        "        pad_int=pad_int,\n",
        "        using_tpu=using_tpu)\n",
        "    \n",
        "    loss_func = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=False)\n",
        "    optimizer = tf.keras.optimizers.Adam(learning_rate, epsilon=tf.keras.backend.epsilon())\n",
        "    temp_input = tf.random.uniform((batch_size, max_seq_len), dtype=tf.int32, minval=5, maxval=6999)\n",
        "    temp_target = tf.random.uniform((batch_size, set_size), dtype=tf.int32, minval=5, maxval=6999)\n",
        "    model.compile(optimizer=optimizer, loss=loss_func)\n",
        "\n",
        "param_count: int = model.count_params()\n",
        "print(f\"The model has {param_count:,} = {param_count * (10**-6):,}M trainable parameters\")\n",
        "stats = FlopCoKeras(model)\n",
        "flops_per_call: int = stats.total_flops\n",
        "macs_per_call: int = stats.total_macs\n",
        "\n",
        "# (add-multiplies per forward pass) * (2 FLOPs/add-multiply) * (3 for forward and backward pass) * (number of examples in dataset) \n",
        "training_flops: float  = macs_per_call * 2 * flops_per_call / macs_per_call * (3 * train_step_calles + val_step_calles)\n",
        "print(f\"FLOPs per call: {flops_per_call:,} = {(flops_per_call * (10 ** -6)):,}M\")\n",
        "print(f\"MACs per call: {macs_per_call:,} = {(macs_per_call * (10 ** -6)):,}M\")\n",
        "\n",
        "del temp_input, temp_target"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Weights and Biases"
      ],
      "metadata": {
        "id": "eRHYWRwmRmef"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%wandb login\n",
        "%notify('waiting for user input')\n",
        "# my API key is 58def12d67e682fb2c89ab27e91e612243568aba"
      ],
      "metadata": {
        "id": "QK4HzQpGRxwY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "run = wandb.init(\n",
        "    project=\"pytorch-intro\",\n",
        "    entity=\"yoniteam\",\n",
        "    name=datetime.datetime.today().strftime(f\"run from %d/%m/%Y\"),\n",
        "    settings=wandb.Settings(start_method=\"thread\"),\n",
        "    config = {\"set size\": set_size,\n",
        "              \"batch size\": batch_size,\n",
        "              \"learning rate\": learning_rate,\n",
        "              \"max seq len\": max_seq_len,\n",
        "              \"num blocks\": num_blocks,\n",
        "              \"model dimention\": d_model,\n",
        "              \"dff\": dff,\n",
        "              \"num heads\": num_heads,\n",
        "              \"dropout rate\": dropout_rate,\n",
        "              \"params\": param_count\n",
        "              })\n",
        "config = wandb.config"
      ],
      "metadata": {
        "id": "hSyTfD8FW01n",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 86
        },
        "outputId": "92fa8a12-07f2-48e6-fcdc-b0d1fc0f2f47"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33myonikremer\u001b[0m (\u001b[33myoniteam\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.12.21"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20220707_132821-5mn3jqy2</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href=\"https://wandb.ai/yoniteam/pytorch-intro/runs/5mn3jqy2\" target=\"_blank\">run from 07/07/2022</a></strong> to <a href=\"https://wandb.ai/yoniteam/pytorch-intro\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5gjCRldwckzR"
      },
      "source": [
        "## Training helper functions"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "@tf.function\n",
        "def contains_pad(inp: tf.Tensor):\n",
        "    bool_ten = tf.math.equal(inp, pad_ten)\n",
        "    nonzero_count = tf.math.count_nonzero(bool_ten)\n",
        "    return nonzero_count > 0"
      ],
      "metadata": {
        "id": "HZf9y_1nCtEa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iRP0mGA1NjXi"
      },
      "source": [
        "### Train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UR6qYltHhh_t"
      },
      "outputs": [],
      "source": [
        "@tf.function(input_signature=(tf.TensorSpec(shape=[batch_size, None], dtype=tf.int32),\n",
        "                              tf.TensorSpec(shape=[batch_size, set_size], dtype=tf.int32)))\n",
        "def train_step(inp: tf.Tensor, outp: tf.Tensor) -> tf.Tensor:\n",
        "    with tf.GradientTape() as tape:\n",
        "        pred: tf.Tensor = model([inp, outp], training=True) \n",
        "        loss_val: tf.Tensor = loss_func(y_true = outp, y_pred = pred)\n",
        "    grads: tf.RaggedTensor = tape.gradient(loss_val, model.trainable_weights)\n",
        "    optimizer.apply_gradients(zip(grads, model.trainable_weights))\n",
        "    return tf.math.reduce_mean(loss_val)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "@tf.autograph.experimental.do_not_convert\n",
        "@tf.function(input_signature=[tf.TensorSpec(shape=[batch_size, max_seq_len], dtype=tf.int32)])\n",
        "def train(batch: tf.Tensor) -> tf.TensorSpec(shape=[], dtype=tf.keras.backend.floatx()):\n",
        "    per_generation_loss: tf.Tensor = tf.zeros([num_sets], dtype=tf.keras.backend.floatx())\n",
        "    i = 0\n",
        "    while i < num_sets:\n",
        "        # The input is of size set_size-TAKE_TO_ACCOUNT\n",
        "        already_predicted: int = i * (set_size + 1)\n",
        "        start_from: int = max(0, already_predicted - max_seq_len)\n",
        "        inp: tf.Tensor = batch[:, start_from:(i + 1) * set_size]\n",
        "        have_pad = tf.map_fn(contains_pad, inp, fn_output_signature=tf.bool, parallel_iterations=batch_size)\n",
        "        if tf.get_static_value(tf.math.reduce_all(have_pad)):\n",
        "            break\n",
        "        outp: tf.TensorSpec(shape=[batch_size, set_size]) = batch[:, (i + 1) * set_size:(i + 2) * set_size]\n",
        "        loss_val: tf.TensorSpec(shape=[], dtype=tf.keras.backend.floatx()) = train_step(inp, outp)\n",
        "        one_hot: tf.TensorSpec(shape=[num_sets], dtype=tf.keras.backend.floatx())\n",
        "        one_hot = tf.one_hot([i], num_sets, dtype=tf.keras.backend.floatx()) * loss_val\n",
        "        per_generation_loss += one_hot\n",
        "        i += 1\n",
        "    train_step_calles += i \n",
        "    return tf.math.reduce_mean(per_generation_loss[:i])\n",
        "    "
      ],
      "metadata": {
        "id": "sSQ8nWVwMuG_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N9vu221UNjXk"
      },
      "source": [
        "### Validate"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "@tf.function(input_signature=(tf.TensorSpec(shape=[batch_size, None], dtype=tf.int32),\n",
        "                                  tf.TensorSpec(shape=[batch_size, set_size], dtype=tf.int32)))\n",
        "def val_step(inp: tf.Tensor, outp: tf.Tensor) -> tf.Tensor:\n",
        "    pred = model([inp, outp], training=False)\n",
        "    loss_val = loss_func(y_true = outp, y_pred = pred)\n",
        "    return tf.math.reduce_mean(loss_val)"
      ],
      "metadata": {
        "id": "gPYi_RT4Ytv_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7NpdkcUkckzT",
        "pycharm": {
          "name": "#%%\n"
        }
      },
      "outputs": [],
      "source": [
        "@tf.function(input_signature=[tf.TensorSpec(shape=[batch_size, max_seq_len], dtype=tf.int32)])\n",
        "def validate(batch: tf.Tensor) -> tf.TensorSpec(shape=[], dtype=tf.keras.backend.floatx()):\n",
        "    per_generation_loss: tf.Tensor = tf.zeros([num_sets], dtype=tf.keras.backend.floatx())\n",
        "    i = 0\n",
        "    while i < num_sets:\n",
        "        # The input is of size set_size-TAKE_TO_ACCOUNT\n",
        "        already_predicted: int = i * (set_size + 1)\n",
        "        start_from: int = max(0, already_predicted - max_seq_len)\n",
        "        inp: tf.Tensor = batch[:, start_from:(i + 1) * set_size]\n",
        "        have_pad = tf.map_fn(contains_pad, inp, fn_output_signature=tf.bool, parallel_iterations=batch_size)\n",
        "        if tf.get_static_value(tf.math.reduce_all(have_pad)):\n",
        "            break\n",
        "        outp: tf.TensorSpec(shape=[batch_size, set_size]) = batch[:, (i + 1) * set_size:(i + 2) * set_size]\n",
        "        loss_val: tf.TensorSpec(shape=[], dtype=tf.keras.backend.floatx()) = val_step(inp, outp)\n",
        "        one_hot: tf.TensorSpec(shape=[num_sets], dtype=tf.keras.backend.floatx())\n",
        "        one_hot = tf.one_hot([i], num_sets, dtype=tf.keras.backend.floatx()) * loss_val\n",
        "        per_generation_loss += one_hot\n",
        "        i += 1\n",
        "    val_step_calles += i\n",
        "    return tf.math.reduce_mean(per_generation_loss[:i])"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Chackpoints"
      ],
      "metadata": {
        "id": "cEcysTey1bEk"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Iuce_A94ckzU",
        "pycharm": {
          "name": "#%%\n"
        }
      },
      "outputs": [],
      "source": [
        "date: str = datetime.datetime.now().strftime('%m%d-%H%M')\n",
        "if device == 'colab':\n",
        "    folder_path: str = \"/drive/MyDrive/final_project/checkpoints/\"\n",
        "else:\n",
        "    folder_path: str = \"C:/yoni/final_project/model/checkpoints/\"\n",
        "check_points_path = f\"{folder_path}{date}\"\n",
        "if not os.path.isdir(folder_path):\n",
        "    os.mkdir(folder_path)\n",
        "if not os.path.isdir(check_points_path):\n",
        "    os.mkdir(check_points_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LZsEGz_vckzT",
        "pycharm": {
          "name": "#%%\n"
        }
      },
      "outputs": [],
      "source": [
        "def check_point(folder_path: str, model: SeTransformer, val_loss: float, train_loss: float, test_loss = None):\n",
        "    \"\"\"Saves the model at the end of each epoch\"\"\"\n",
        "    # (add-multiplies per forward pass) * (2 FLOPs/add-multiply) * \n",
        "    # * (3 for forward and backward pass) * (number of examples in dataset) \n",
        "    num_ops: float  = macs_per_call * 2 * flops_per_call / macs_per_call * (3 * train_step_calles + val_step_calles)\n",
        "    peta_ops: float = num_ops * (10 ** (-15))\n",
        "    tf.keras.models.save_model(model = model, filepath = folder_path, save_format='tf', overwrite=True)\n",
        "    artifact = wandb.Artifact('new_artifact', type='my_model', description = f\"the model after {num_ops:,} operations\")\n",
        "    artifact.add_dir(f'after_{training_flops:,}_ops/')\n",
        "    run.log_artifact(artifact)\n",
        "    print(\"Saved checkpoint\")\n",
        "    %notify(\"Saved checkpoint\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "00auA3LZwKvf"
      },
      "outputs": [],
      "source": [
        "train_loss, val_loss = float('inf'), float('inf')\n",
        "best_val_loss = float('inf')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def loss_to_prob(loss: float) -> float:\n",
        "    return math.exp(-loss)"
      ],
      "metadata": {
        "id": "VQENw4qSEssJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RN8rmbrNW0-Z"
      },
      "source": [
        "## The actual training loop!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nHktVH98kp4B",
        "pycharm": {
          "name": "#%%\n"
        }
      },
      "outputs": [],
      "source": [
        "def train_loop():\n",
        "    epochs: int = 1000000  # Train until the cloud disconnects or the model stops improving\n",
        "    per_epoch_train_loss: List[float] = []\n",
        "    per_epoch_val_loss: List[float] = []\n",
        "    print(f\"number of train batches per epoch: {len(list_train_set)}\")\n",
        "    last_save_time = time.time()\n",
        "    global epoch: int = 0\n",
        "    global batch_num: int = 0\n",
        "    global val_step_calles: int = 0\n",
        "    global train_step_calles: int = 0\n",
        "    for epoch in range(epochs):\n",
        "        print(f\"epoch number: {epoch}\")\n",
        "        per_batch_train_loss: List[float] = []\n",
        "        per_batch_val_loss: List[float] = []\n",
        "        for batch_num in tqdm.tqdm(range(len(list_train_set))):  # tqdm is a progress bar\n",
        "            train_loss: tf.Tensor = train(list_train_set[batch_num])\n",
        "            float_val_loss = tf.keras.backend.eval(train_loss).item()\n",
        "            per_batch_train_loss.append(train_loss)\n",
        "            if batch_num % 8 == 0:  # 8 is number of training batches/number of val batches\n",
        "                # because training set is 80% of the data and val set is 10%\n",
        "                next_val_batch: tf.Tensor = list_val_set[batch_num // 8]\n",
        "                val_loss: tf.Tensor = validate(next_val_batch)\n",
        "                float_val_loss = tf.keras.backend.eval(val_loss).item()\n",
        "                per_batch_val_loss.append(val_loss)\n",
        "                wandb.log({\"epoch\": epoch, \"batch\": batch_num, \"per batch train loss\": train_loss, \n",
        "                        \"per batch val loss\": val_loss})\n",
        "                if time.time() - last_save_time > 3600.0 and val_loss < math.log(vocab_size):  \n",
        "                    # If the last save is more than a hour (3600 sec) ago\n",
        "                    # and if the predictions are not random\n",
        "                    check_point(check_points_path, model, per_epoch_val_loss[-1], per_epoch_train_loss[-1])\n",
        "                    last_save_time = time.time()\n",
        "                elif train_loss < 0.01:\n",
        "                    title: str = \"Over fitting or data leak\"\n",
        "                    message = f\"Training loss is {train_loss} and val loss is {val_loss} in the latest batch\"\n",
        "                    wandb.alert(title=title, text=message)\n",
        "                    print(title)\n",
        "                    print(message)\n",
        "                    %notify(title)\n",
        "                    return train_loss, val_loss\n",
        "                elif time.time() - last_save_time > 1800.0 and val_loss >= math.log(vocab_size):\n",
        "                    # if the prob of every token is 1/vocab_size, the loss is\n",
        "                    # -ln(1/vocab_size) = ln(vocab_size) \n",
        "                    # by the logrithem rule log(a^x)=xlog(a) where x = -1\n",
        "                    # if after 30 mins of training, the model predictions are still random\n",
        "                    title: str = \"Under fitting\"\n",
        "                    message = f\"training loss is {train_loss} and val loss is {val_loss} in the latest batch\"\n",
        "                    wandb.alert(title=title, text=message)\n",
        "                    print(title)\n",
        "                    print(message)\n",
        "                    %notify(title)\n",
        "                    return train_loss, val_loss\n",
        "        per_epoch_train_loss.append(statistics.mean(per_batch_train_loss))\n",
        "        per_epoch_val_loss.append(statistics.mean(per_batch_val_loss))\n",
        "        print(f\"train_loss: {per_epoch_train_loss[-1]}\")\n",
        "        print(f\"prob of right ans train: {loss_to_prob(per_epoch_train_loss[-1])}\")\n",
        "        print(f\"val_loss: {per_epoch_val_loss[-1]}\")\n",
        "        print(f\"prob of right ans val: {loss_to_prob(per_epoch_val_loss[-1])}\")\n",
        "        if len(per_epoch_val_loss) > 1:\n",
        "            if per_epoch_val_loss[-1] >= per_epoch_val_loss[-2]:\n",
        "                print(\"Validation loss increased. Stopped training\")\n",
        "                %notify(\"Validation loss increased. Stopped training\")\n",
        "                return per_epoch_train_loss[-1], per_epoch_val_loss[-1]\n",
        "        check_point(check_points_path, model, per_epoch_val_loss[-1], per_epoch_train_loss[-1])\n",
        "        last_save_time = time.time()\n",
        "        print(\"Saved checkpoint\")\n",
        "        %notify(\"Epoche ended, Saved checkpoint\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "with strategy.scope():\n",
        "    train_loss, val_loss = train_loop()"
      ],
      "metadata": {
        "id": "g5MukK3ynG7v",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dca87c06-0140-41d9-c5bd-1e71ea9c9289"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "number of train batches per epoch: 8401\n",
            "epoch number: 0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/8401 [00:00<?, ?it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING:tensorflow:AutoGraph could not transform <function train at 0x7f5fd4c5c290> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: name 'fscope' is not defined\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
            "WARNING: AutoGraph could not transform <function train at 0x7f5fd4c5c290> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: name 'fscope' is not defined\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "reproduce error"
      ],
      "metadata": {
        "id": "i48dY189QR1i"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "resolver = tf.distribute.cluster_resolver.TPUClusterResolver();\n",
        "tf.config.experimental_connect_to_cluster(resolver);\n",
        "tf.tpu.experimental.initialize_tpu_system(resolver);\n",
        "strategy = tf.distribute.TPUStrategy(resolver);"
      ],
      "metadata": {
        "id": "V93HsJW-Vth-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with strategy.scope():\n",
        "    exm_model = tf.keras.Sequential([\n",
        "        tf.keras.layers.Dense(2, activation=\"relu\", name=\"layer1\"),\n",
        "        tf.keras.layers.Dense(3, activation=\"relu\", name=\"layer2\"),\n",
        "        tf.keras.layers.Dense(1, name=\"layer3\"),\n",
        "    ])\n",
        "    exm_optimizer = tf.keras.optimizers.Adam()\n",
        "    mse = tf.keras.losses.MeanSquaredError()\n",
        "\n",
        "@tf.function(input_signature=(tf.TensorSpec(shape=[3,3], dtype=tf.int32),\n",
        "                              tf.TensorSpec(shape=[3], dtype=tf.int32)))\n",
        "def exm_train_step(inp: tf.Tensor, outp: tf.Tensor) -> tf.Tensor:\n",
        "    with tf.GradientTape() as tape:\n",
        "        pred: tf.Tensor = exm_model(inp) \n",
        "        loss_val: tf.Tensor = mse(outp, pred)\n",
        "    grads: tf.RaggedTensor = tape.gradient(loss_val, model.trainable_weights)\n",
        "    exm_optimizer.apply_gradients(zip(grads, model.trainable_weights))\n",
        "    return tf.math.reduce_mean(loss_val)\n",
        "\n",
        "\n",
        "exm_inp = tf.random.uniform(shape=[3, 3], dtype=tf.int32, maxval=100, minval=0)\n",
        "exm_out = tf.random.uniform(shape=[3], dtype=tf.int32, maxval=100, minval=0)\n",
        "\n",
        "\n",
        "exm_train_step(exm_inp, exm_out)"
      ],
      "metadata": {
        "id": "6EondR_UQUe4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z-iopedNNjXs"
      },
      "source": [
        "## After training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1VtC8sP_NjXu"
      },
      "outputs": [],
      "source": [
        "test_loss = statistics.mean([validate(test_batch) for test_batch in tqdm.tqdm(list_test_set)])\n",
        "print(f\"Test loss: {test_loss}\")\n",
        "check_point(check_points_path, model, val_loss, train_loss, test_loss)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "create_models.ipynb",
      "provenance": []
    },
    "gpuClass": "standard",
    "kernel_info": {
      "name": "python3"
    },
    "kernelspec": {
      "display_name": "Python 3.9.12 ('base')",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.12"
    },
    "nteract": {
      "version": "nteract-front-end@1.0.0"
    },
    "vscode": {
      "interpreter": {
        "hash": "4c667eb41e29edd16195f2712b5916a29b36d4e6f17fe7c0a7edbb7a73b8ba8a"
      }
    },
    "accelerator": "TPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}