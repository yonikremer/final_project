{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZZf-fbj50Kqc"
      },
      "source": [
        "# Imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "hzlmid2TRUhO"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Note: you may need to restart the kernel to use updated packages.\n",
            "Note: you may need to restart the kernel to use updated packages.\n",
            "Note: you may need to restart the kernel to use updated packages.\n",
            "Note: you may need to restart the kernel to use updated packages.\n",
            "Note: you may need to restart the kernel to use updated packages.\n",
            "Note: you may need to restart the kernel to use updated packages.\n",
            "Note: you may need to restart the kernel to use updated packages.\n",
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        }
      ],
      "source": [
        "import sys\n",
        "from typing import Set\n",
        "modules: Set[str] = set(sys.modules)\n",
        "%pip install -q pip --upgrade\n",
        "if not ('jupyternotify') in modules:\n",
        "    %pip install -q jupyternotify\n",
        "import numpy as np\n",
        "if np.__version__ < \"1.2.4\":\n",
        "    %pip install -q numpy==1.2.4\n",
        "if not ('folium' in modules):\n",
        "    %pip install -q folium==0.2.1\n",
        "    modules.add('folium')\n",
        "if not ('imgaug' in modules):\n",
        "    %pip install -q imgaug==0.2.6\n",
        "    modules.add('imgaug')\n",
        "if not ('tensorflow_text' in modules):\n",
        "    %pip install -q tensorflow_text==2.9.0\n",
        "    modules.add('tensorflow_text')\n",
        "if not ('seaborn' in modules):\n",
        "    %pip -q install -q seaborn\n",
        "    modules.add('seaborn')\n",
        "if not ('tqdm' in modules):\n",
        "    %pip install -q tqdm\n",
        "    modules.add('tqdm')\n",
        "if not ('matplotlib' in modules):\n",
        "    %pip install -q matplotlib\n",
        "    modules.add('matplotlib')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "gather": {
          "logged": 1644854036589
        },
        "id": "MsfMr-Qod_nl",
        "outputId": "f28ea6ce-2590-4e1b-bdcf-c2b78ca6190a"
      },
      "outputs": [
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[1;32mc:\\yoni\\final_project\\model\\create_models.ipynb Cell 3'\u001b[0m in \u001b[0;36m<cell line: 9>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/yoni/final_project/model/create_models.ipynb#ch0000002?line=6'>7</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mstatistics\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/yoni/final_project/model/create_models.ipynb#ch0000002?line=7'>8</a>\u001b[0m \u001b[39m# NOT-standart liberies:\u001b[39;00m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/yoni/final_project/model/create_models.ipynb#ch0000002?line=8'>9</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mtf\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/yoni/final_project/model/create_models.ipynb#ch0000002?line=9'>10</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mtensorflow_text\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mtf_text\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/yoni/final_project/model/create_models.ipynb#ch0000002?line=10'>11</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mpandas\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mpd\u001b[39;00m\n",
            "File \u001b[1;32mc:\\Users\\yonik\\anaconda3\\lib\\site-packages\\tensorflow\\__init__.py:37\u001b[0m, in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     34\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39msys\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39m_sys\u001b[39;00m\n\u001b[0;32m     35\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mtyping\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39m_typing\u001b[39;00m\n\u001b[1;32m---> 37\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpython\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mtools\u001b[39;00m \u001b[39mimport\u001b[39;00m module_util \u001b[39mas\u001b[39;00m _module_util\n\u001b[0;32m     38\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpython\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mutil\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mlazy_loader\u001b[39;00m \u001b[39mimport\u001b[39;00m LazyLoader \u001b[39mas\u001b[39;00m _LazyLoader\n\u001b[0;32m     40\u001b[0m \u001b[39m# Make sure code inside the TensorFlow codebase can use tf2.enabled() at import.\u001b[39;00m\n",
            "File \u001b[1;32mc:\\Users\\yonik\\anaconda3\\lib\\site-packages\\tensorflow\\python\\__init__.py:45\u001b[0m, in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     43\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpython\u001b[39;00m \u001b[39mimport\u001b[39;00m distribute\n\u001b[0;32m     44\u001b[0m \u001b[39m# from tensorflow.python import keras\u001b[39;00m\n\u001b[1;32m---> 45\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpython\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mfeature_column\u001b[39;00m \u001b[39mimport\u001b[39;00m feature_column_lib \u001b[39mas\u001b[39;00m feature_column\n\u001b[0;32m     46\u001b[0m \u001b[39m# from tensorflow.python.layers import layers\u001b[39;00m\n\u001b[0;32m     47\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpython\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mmodule\u001b[39;00m \u001b[39mimport\u001b[39;00m module\n",
            "File \u001b[1;32mc:\\Users\\yonik\\anaconda3\\lib\\site-packages\\tensorflow\\python\\feature_column\\feature_column_lib.py:18\u001b[0m, in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[39m\"\"\"FeatureColumns: tools for ingesting and representing features.\"\"\"\u001b[39;00m\n\u001b[0;32m     17\u001b[0m \u001b[39m# pylint: disable=unused-import,line-too-long,wildcard-import,g-bad-import-order\u001b[39;00m\n\u001b[1;32m---> 18\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpython\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mfeature_column\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mfeature_column\u001b[39;00m \u001b[39mimport\u001b[39;00m \u001b[39m*\u001b[39m\n\u001b[0;32m     19\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpython\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mfeature_column\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mfeature_column_v2\u001b[39;00m \u001b[39mimport\u001b[39;00m \u001b[39m*\u001b[39m\n\u001b[0;32m     20\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpython\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mfeature_column\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39msequence_feature_column\u001b[39;00m \u001b[39mimport\u001b[39;00m \u001b[39m*\u001b[39m\n",
            "File \u001b[1;32mc:\\Users\\yonik\\anaconda3\\lib\\site-packages\\tensorflow\\python\\feature_column\\feature_column.py:143\u001b[0m, in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m    141\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpython\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mframework\u001b[39;00m \u001b[39mimport\u001b[39;00m sparse_tensor \u001b[39mas\u001b[39;00m sparse_tensor_lib\n\u001b[0;32m    142\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpython\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mframework\u001b[39;00m \u001b[39mimport\u001b[39;00m tensor_shape\n\u001b[1;32m--> 143\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpython\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mlayers\u001b[39;00m \u001b[39mimport\u001b[39;00m base\n\u001b[0;32m    144\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpython\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mops\u001b[39;00m \u001b[39mimport\u001b[39;00m array_ops\n\u001b[0;32m    145\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpython\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mops\u001b[39;00m \u001b[39mimport\u001b[39;00m check_ops\n",
            "File \u001b[1;32mc:\\Users\\yonik\\anaconda3\\lib\\site-packages\\tensorflow\\python\\layers\\base.py:16\u001b[0m, in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[39m# Copyright 2015 The TensorFlow Authors. All Rights Reserved.\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[39m#\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[39m# Licensed under the Apache License, Version 2.0 (the \"License\");\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[39m# limitations under the License.\u001b[39;00m\n\u001b[0;32m     14\u001b[0m \u001b[39m# =============================================================================\u001b[39;00m\n\u001b[0;32m     15\u001b[0m \u001b[39m\"\"\"Contains the base Layer class, from which all layers inherit.\"\"\"\u001b[39;00m\n\u001b[1;32m---> 16\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpython\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mkeras\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mlegacy_tf_layers\u001b[39;00m \u001b[39mimport\u001b[39;00m base\n\u001b[0;32m     18\u001b[0m InputSpec \u001b[39m=\u001b[39m base\u001b[39m.\u001b[39mInputSpec\n\u001b[0;32m     20\u001b[0m keras_style_scope \u001b[39m=\u001b[39m base\u001b[39m.\u001b[39mkeras_style_scope\n",
            "File \u001b[1;32mc:\\Users\\yonik\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\__init__.py:25\u001b[0m, in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     22\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpython\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mkeras\u001b[39;00m \u001b[39mimport\u001b[39;00m distribute\n\u001b[0;32m     24\u001b[0m \u001b[39m# See b/110718070#comment18 for more details about this import.\u001b[39;00m\n\u001b[1;32m---> 25\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpython\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mkeras\u001b[39;00m \u001b[39mimport\u001b[39;00m models\n\u001b[0;32m     27\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpython\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mkeras\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mengine\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39minput_layer\u001b[39;00m \u001b[39mimport\u001b[39;00m Input\n\u001b[0;32m     28\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpython\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mkeras\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mengine\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39msequential\u001b[39;00m \u001b[39mimport\u001b[39;00m Sequential\n",
            "File \u001b[1;32mc:\\Users\\yonik\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\models.py:20\u001b[0m, in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpython\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mframework\u001b[39;00m \u001b[39mimport\u001b[39;00m ops\n\u001b[0;32m     19\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpython\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mkeras\u001b[39;00m \u001b[39mimport\u001b[39;00m backend\n\u001b[1;32m---> 20\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpython\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mkeras\u001b[39;00m \u001b[39mimport\u001b[39;00m metrics \u001b[39mas\u001b[39;00m metrics_module\n\u001b[0;32m     21\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpython\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mkeras\u001b[39;00m \u001b[39mimport\u001b[39;00m optimizer_v1\n\u001b[0;32m     22\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpython\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mkeras\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mengine\u001b[39;00m \u001b[39mimport\u001b[39;00m functional\n",
            "File \u001b[1;32mc:\\Users\\yonik\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\metrics.py:34\u001b[0m, in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     32\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpython\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mframework\u001b[39;00m \u001b[39mimport\u001b[39;00m ops\n\u001b[0;32m     33\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpython\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mframework\u001b[39;00m \u001b[39mimport\u001b[39;00m tensor_shape\n\u001b[1;32m---> 34\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpython\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mkeras\u001b[39;00m \u001b[39mimport\u001b[39;00m activations\n\u001b[0;32m     35\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpython\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mkeras\u001b[39;00m \u001b[39mimport\u001b[39;00m backend\n\u001b[0;32m     36\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpython\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mkeras\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mengine\u001b[39;00m \u001b[39mimport\u001b[39;00m base_layer\n",
            "File \u001b[1;32mc:\\Users\\yonik\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\activations.py:18\u001b[0m, in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[39m\"\"\"Built-in activation functions.\"\"\"\u001b[39;00m\n\u001b[0;32m     17\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpython\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mkeras\u001b[39;00m \u001b[39mimport\u001b[39;00m backend\n\u001b[1;32m---> 18\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpython\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mkeras\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mlayers\u001b[39;00m \u001b[39mimport\u001b[39;00m advanced_activations\n\u001b[0;32m     19\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpython\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mkeras\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mutils\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mgeneric_utils\u001b[39;00m \u001b[39mimport\u001b[39;00m deserialize_keras_object\n\u001b[0;32m     20\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpython\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mkeras\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mutils\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mgeneric_utils\u001b[39;00m \u001b[39mimport\u001b[39;00m serialize_keras_object\n",
            "File \u001b[1;32mc:\\Users\\yonik\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\layers\\__init__.py:68\u001b[0m, in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     65\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpython\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mkeras\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mlayers\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mconvolutional\u001b[39;00m \u001b[39mimport\u001b[39;00m Cropping3D\n\u001b[0;32m     67\u001b[0m \u001b[39m# Core layers.\u001b[39;00m\n\u001b[1;32m---> 68\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpython\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mkeras\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mlayers\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mcore\u001b[39;00m \u001b[39mimport\u001b[39;00m Masking\n\u001b[0;32m     69\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpython\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mkeras\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mlayers\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mcore\u001b[39;00m \u001b[39mimport\u001b[39;00m Dropout\n\u001b[0;32m     70\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpython\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mkeras\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mlayers\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mcore\u001b[39;00m \u001b[39mimport\u001b[39;00m SpatialDropout1D\n",
            "File \u001b[1;32mc:\\Users\\yonik\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\layers\\core.py:54\u001b[0m, in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     52\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpython\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mops\u001b[39;00m \u001b[39mimport\u001b[39;00m nn_ops\n\u001b[0;32m     53\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpython\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mops\u001b[39;00m \u001b[39mimport\u001b[39;00m sparse_ops\n\u001b[1;32m---> 54\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpython\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mops\u001b[39;00m \u001b[39mimport\u001b[39;00m standard_ops\n\u001b[0;32m     55\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpython\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mops\u001b[39;00m \u001b[39mimport\u001b[39;00m variable_scope\n\u001b[0;32m     56\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpython\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mops\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mragged\u001b[39;00m \u001b[39mimport\u001b[39;00m ragged_getitem\n",
            "File \u001b[1;32mc:\\Users\\yonik\\anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\standard_ops.py:108\u001b[0m, in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m    105\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpython\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mops\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mvariables\u001b[39;00m \u001b[39mimport\u001b[39;00m \u001b[39m*\u001b[39m\n\u001b[0;32m    106\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpython\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mops\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mparallel_for\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mcontrol_flow_ops\u001b[39;00m \u001b[39mimport\u001b[39;00m vectorized_map\n\u001b[1;32m--> 108\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpython\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mcompiler\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mtensorrt\u001b[39;00m \u001b[39mimport\u001b[39;00m trt_convert \u001b[39mas\u001b[39;00m trt\n\u001b[0;32m    110\u001b[0m \u001b[39m# pylint: enable=wildcard-import\u001b[39;00m\n\u001b[0;32m    111\u001b[0m \u001b[39m# pylint: enable=g-bad-import-order\u001b[39;00m\n\u001b[0;32m    112\u001b[0m \n\u001b[0;32m    113\u001b[0m \n\u001b[0;32m    114\u001b[0m \u001b[39m# These modules were imported to set up RaggedTensor operators and dispatchers:\u001b[39;00m\n\u001b[0;32m    115\u001b[0m \u001b[39mdel\u001b[39;00m _ragged_dispatch, _ragged_operators\n",
            "File \u001b[1;32mc:\\Users\\yonik\\anaconda3\\lib\\site-packages\\tensorflow\\python\\compiler\\tensorrt\\__init__.py:18\u001b[0m, in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[39m\"\"\"Exposes the python wrapper for TensorRT graph transforms.\"\"\"\u001b[39;00m\n\u001b[0;32m     17\u001b[0m \u001b[39m# pylint: disable=unused-import,line-too-long\u001b[39;00m\n\u001b[1;32m---> 18\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpython\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mcompiler\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mtensorrt\u001b[39;00m \u001b[39mimport\u001b[39;00m trt_convert \u001b[39mas\u001b[39;00m trt\n",
            "File \u001b[1;32mc:\\Users\\yonik\\anaconda3\\lib\\site-packages\\tensorflow\\python\\compiler\\tensorrt\\trt_convert.py:33\u001b[0m, in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     31\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpython\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39meager\u001b[39;00m \u001b[39mimport\u001b[39;00m context\n\u001b[0;32m     32\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpython\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39meager\u001b[39;00m \u001b[39mimport\u001b[39;00m wrap_function\n\u001b[1;32m---> 33\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpython\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mframework\u001b[39;00m \u001b[39mimport\u001b[39;00m convert_to_constants\n\u001b[0;32m     34\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpython\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mframework\u001b[39;00m \u001b[39mimport\u001b[39;00m dtypes\n\u001b[0;32m     35\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpython\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mframework\u001b[39;00m \u001b[39mimport\u001b[39;00m errors\n",
            "File \u001b[1;32mc:\\Users\\yonik\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\convert_to_constants.py:33\u001b[0m, in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     31\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpython\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mframework\u001b[39;00m \u001b[39mimport\u001b[39;00m ops\n\u001b[0;32m     32\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpython\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mframework\u001b[39;00m \u001b[39mimport\u001b[39;00m tensor_util\n\u001b[1;32m---> 33\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpython\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mgrappler\u001b[39;00m \u001b[39mimport\u001b[39;00m tf_optimizer\n\u001b[0;32m     34\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpython\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mops\u001b[39;00m \u001b[39mimport\u001b[39;00m array_ops\n\u001b[0;32m     35\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpython\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mops\u001b[39;00m \u001b[39mimport\u001b[39;00m variables\n",
            "File \u001b[1;32mc:\\Users\\yonik\\anaconda3\\lib\\site-packages\\tensorflow\\python\\grappler\\tf_optimizer.py:22\u001b[0m, in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     20\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mcore\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mprotobuf\u001b[39;00m \u001b[39mimport\u001b[39;00m config_pb2\n\u001b[0;32m     21\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpython\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mgrappler\u001b[39;00m \u001b[39mimport\u001b[39;00m _pywrap_tf_optimizer \u001b[39mas\u001b[39;00m tf_opt\n\u001b[1;32m---> 22\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpython\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mgrappler\u001b[39;00m \u001b[39mimport\u001b[39;00m cluster \u001b[39mas\u001b[39;00m gcluster\n\u001b[0;32m     24\u001b[0m _OPTIMIZE_GRAPH_CLUSTER_LOCK \u001b[39m=\u001b[39m threading\u001b[39m.\u001b[39mLock()\n\u001b[0;32m     27\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mOptimizeGraph\u001b[39m(config_proto,\n\u001b[0;32m     28\u001b[0m                   metagraph,\n\u001b[0;32m     29\u001b[0m                   verbose\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m,\n\u001b[0;32m     30\u001b[0m                   graph_id\u001b[39m=\u001b[39m\u001b[39mb\u001b[39m\u001b[39m'\u001b[39m\u001b[39mgraph_to_optimize\u001b[39m\u001b[39m'\u001b[39m,\n\u001b[0;32m     31\u001b[0m                   cluster\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m,\n\u001b[0;32m     32\u001b[0m                   strip_default_attributes\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m):\n",
            "File \u001b[1;32m<frozen importlib._bootstrap>:1007\u001b[0m, in \u001b[0;36m_find_and_load\u001b[1;34m(name, import_)\u001b[0m\n",
            "File \u001b[1;32m<frozen importlib._bootstrap>:986\u001b[0m, in \u001b[0;36m_find_and_load_unlocked\u001b[1;34m(name, import_)\u001b[0m\n",
            "File \u001b[1;32m<frozen importlib._bootstrap>:680\u001b[0m, in \u001b[0;36m_load_unlocked\u001b[1;34m(spec)\u001b[0m\n",
            "File \u001b[1;32m<frozen importlib._bootstrap_external>:846\u001b[0m, in \u001b[0;36mexec_module\u001b[1;34m(self, module)\u001b[0m\n",
            "File \u001b[1;32m<frozen importlib._bootstrap_external>:941\u001b[0m, in \u001b[0;36mget_code\u001b[1;34m(self, fullname)\u001b[0m\n",
            "File \u001b[1;32m<frozen importlib._bootstrap_external>:1039\u001b[0m, in \u001b[0;36mget_data\u001b[1;34m(self, path)\u001b[0m\n",
            "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "# standart liberies:\n",
        "from typing import List, Optional, Tuple\n",
        "import datetime\n",
        "import os\n",
        "import csv\n",
        "import random\n",
        "import statistics\n",
        "# NOT-standart liberies:\n",
        "import tensorflow as tf\n",
        "import tensorflow_text as tf_text\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import numpy as np\n",
        "import tqdm\n",
        "import matplotlib.pyplot as plt\n",
        "%load_ext jupyternotify"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "gather": {
          "logged": 1644854037100
        },
        "id": "SzaglEQ-kp2n",
        "outputId": "89ae89e9-984e-48a8-f7d9-fa82f971a609",
        "pycharm": {
          "name": "#%%\n"
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Python version: 3.7.13 (default, Apr 24 2022, 01:04:09) \n",
            "[GCC 7.5.0]\n",
            "IPython version: 7.34.0\n",
            "Tensorflow version: 2.9.1\n",
            "tf text version: 2.9.0\n"
          ]
        }
      ],
      "source": [
        "print(f\"Python version: {sys.version}\")\n",
        "print(f\"Tensorflow version: {tf.__version__}\")\n",
        "print(f\"tf text version: {tf_text.__version__}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rJGjWnfTc6DI",
        "outputId": "78801a62-70a2-4f5c-e611-2fc4ca33e08e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "GPU info:/n\n",
            "NVIDIA-SMI has failed because it couldn't communicate with the NVIDIA driver. Make sure that the latest NVIDIA driver is installed and running.\n",
            "\n"
          ]
        }
      ],
      "source": [
        "print('GPU info:/n')\n",
        "!nvidia-smi"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "91ZJ0-RZIx6j"
      },
      "source": [
        "# Settings"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1644854038983
        },
        "id": "2mp2yFTEkp2u",
        "pycharm": {
          "name": "#%%\n"
        }
      },
      "outputs": [],
      "source": [
        "tf.random.set_seed(0)\n",
        "random.seed(0)\n",
        "tf.keras.backend.set_floatx('float16')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1644859230857
        },
        "id": "FqDAqgl5UV58",
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": [
        "device: str\n",
        "if 'google' in modules:\n",
        "    device = 'colab'\n",
        "else:\n",
        "    device = 'locally'\n",
        "curr_folder = os.getcwd()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "id": "B5rtigmHckyv"
      },
      "source": [
        "# Hyper-Parameters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bWmh89nVckyw",
        "pycharm": {
          "name": "#%%\n"
        }
      },
      "outputs": [],
      "source": [
        "set_size: int = 32\n",
        "batch_size: int = 16\n",
        "learning_rate: float = 0.001\n",
        "\n",
        "max_seq_len: int = 1024\n",
        "\n",
        "num_blocks: int = 4\n",
        "d_model: int = 128\n",
        "dff: int = 256\n",
        "num_heads: int = 8\n",
        "dropout_rate: float = 0.1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yVR1oJRD0NtO"
      },
      "source": [
        "# Data loading"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "gather": {
          "logged": 1644857858611
        },
        "id": "pn1UfAXQwlQX",
        "outputId": "99c146f6-68c5-405a-f8b3-947c0d4df8c3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Drive already mounted at /drive; to attempt to forcibly remount, call drive.mount(\"/drive\", force_remount=True).\n",
            "(30279, 2)\n"
          ]
        }
      ],
      "source": [
        "if device == 'colab':  # If notebook is ran on colab\n",
        "    from google.colab import drive\n",
        "    if not os.path.isdir('/drive'):\n",
        "        drive.mount('/drive')\n",
        "    df: pd.DataFrame = pd.read_csv('/drive/MyDrive/final_project/wikipedia_articles.csv')\n",
        "else:  # If notebook is ran on my laptop\n",
        "    df: pd.DataFrame = pd.read_csv('wiki_data/articles.csv')\n",
        "print(df.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IW43lG6iUV6G",
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "outputId": "d3371b8b-a0a2-4318-fb38-e01a491b9d73"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "There are 30279 data points\n",
            "The length of the longest text IN CHARACTERS is: 141803\n",
            "The length of the shortest text IN CHARACTERS is: 816\n"
          ]
        }
      ],
      "source": [
        "df: pd.Series = df['text']\n",
        "data_list: List[str] = df.to_list()\n",
        "DATA_SIZE = len(data_list)\n",
        "print(f\"There are {DATA_SIZE} data points\")\n",
        "string_lengths: List[int] = [len(data_point) for data_point in data_list]\n",
        "max_string_len = max(string_lengths)\n",
        "print(f\"The length of the longest text IN CHARACTERS is: {max_string_len}\")\n",
        "min_string_len = min(string_lengths)\n",
        "print(f\"The length of the shortest text IN CHARACTERS is: {min_string_len}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "id": "87Putqz6kp20"
      },
      "source": [
        "## Creating the vocabulary"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KBhC3SPyMi9n"
      },
      "outputs": [],
      "source": [
        "# %%time\n",
        "bert_tokenizer_params: dict = dict(lower_case=True)\n",
        "VOCAB_SIZE: int = 8192  # Always the same for all models\n",
        "\n",
        "if device == 'colab':  # If notebook is ran on colab\n",
        "    path = '/drive/MyDrive/final_project/look_up_table.txt'\n",
        "else:  # If notebook is ran on my laptop\n",
        "    path = 'C:/yoni/final_project/model/look_up_table.txt'\n",
        "\n",
        "reserved_tokens: List[str] = [\"[PAD]\", \"[UNK]\", \"[START]\", \"[END]\", \"[MASK]\"]\n",
        "\n",
        "if os.path.exists(path):\n",
        "    with open(path, 'r') as f:\n",
        "        vocab: List[str] = f.read().split()\n",
        "else:\n",
        "    bert_vocab_args: dict = dict(\n",
        "        # The target vocabulary size\n",
        "        vocab_size = VOCAB_SIZE,\n",
        "        # Reserved tokens that must be included in the vocabulary\n",
        "        reserved_tokens=reserved_tokens,\n",
        "        # Arguments for `tf_text.BertTokenizer`\n",
        "        bert_tokenizer_params=bert_tokenizer_params,\n",
        "        # Arguments for `wordpiece_vocab.wordpiece_tokenizer_learner_lib.learn`\n",
        "        learn_params={},\n",
        "    )\n",
        "    tensor_list: List = [tf.convert_to_tensor(data_point) for data_point in data_list]\n",
        "    data_set: tf.data.Dataset = tf.data.Dataset.from_tensor_slices(tensor_list)\n",
        "    # I already ran this code and saved the file to C:/yoni/final_project/model/look_up_table.txt\n",
        "    vocab: List[str] = bert_vocab_from_dataset.bert_vocab_from_dataset(\n",
        "        data_set,\n",
        "        **bert_vocab_args,)\n",
        "    with open('C:/yoni/final_project/model/look_up_table.txt', 'w') as f:\n",
        "        for token in vocab:\n",
        "            f.write(token + ' ')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4IZ5uxlJEoi3",
        "outputId": "50274392-e68b-4d19-9cf4-0d03068dc73e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "the type of the items in vocab: <class 'str'>\n",
            "the first 15 items in vocab: ['[PAD]', '[UNK]', '[START]', '[END]', '[MASK]', \"'\", ',', '.', '0', '1', '2', '3', '4', '5', '6']\n",
            " the length of vocab: 7882\n"
          ]
        }
      ],
      "source": [
        "print(f\"the type of the items in vocab: {type(vocab[0])}\")\n",
        "print(f\"the first 15 items in vocab: {vocab[:15]}\")\n",
        "print(f\" the length of vocab: {len(vocab)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hndA44nhFw6I",
        "outputId": "f594d4c2-129c-4be8-d5c2-e34775c0680e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " the type of the items in tensor_vocab is: <class 'tensorflow.python.framework.ops.EagerTensor'>\n",
            " the data type of the tensors in tensor_vocab is: <dtype: 'string'>\n"
          ]
        }
      ],
      "source": [
        "tensor_vocab: List[tf.Tensor] = [tf.convert_to_tensor(token_key, dtype=tf.string) for token_key in vocab]  # dtype = tf.String\n",
        "print(f\" the type of the items in tensor_vocab is: {type(tensor_vocab[0])}\")\n",
        "print(f\" the data type of the tensors in tensor_vocab is: {tensor_vocab[0].dtype}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "id": "lD6QCFLAkp2_"
      },
      "source": [
        "## Creating the tokenizer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HihwIsrKD7C9"
      },
      "outputs": [],
      "source": [
        "lookup_table = tf.lookup.StaticVocabularyTable(\n",
        "    tf.lookup.KeyValueTensorInitializer(\n",
        "        keys=tensor_vocab,\n",
        "        key_dtype=tf.string,\n",
        "        values=tf.range(tf.size(vocab, out_type=tf.int64), dtype=tf.int64),\n",
        "        value_dtype=tf.int64),\n",
        "    num_oov_buckets=1\n",
        ")\n",
        "tokenizer = tf_text.BertTokenizer(lookup_table, **bert_tokenizer_params)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "id": "A73Lbgg6kp3R"
      },
      "source": [
        "## Tokenizing the data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mLxV5l562-x2"
      },
      "outputs": [],
      "source": [
        "# START: int = tf.argmax(tf.constant(reserved_tokens) == \"[START]\")  # The value of the start token\n",
        "# END: int = tf.argmax(tf.constant(reserved_tokens) == \"[END]\")  # The value of the end token\n",
        "# starts = tf.cast(tf.Variable([START]), dtype = tf.int32)  # Tensor of shape [1] and dtype int\n",
        "# ends = tf.cast(tf.Variable([END]), dtype = tf.int32)  # Tensor of shape [1] and dtype int\n",
        "starts = tf.constant([2], dtype=tf.int32)\n",
        "ends = tf.constant([3], dtype=tf.int32)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4gPxVc7tkp3X",
        "pycharm": {
          "name": "#%%\n"
        }
      },
      "outputs": [],
      "source": [
        "def tokenize_string(text: str) -> tf.Tensor:\n",
        "    \"\"\"Converts string to tensor\"\"\"\n",
        "    ragged: tf.RaggedTensor = tokenizer.tokenize(text)[0, :]\n",
        "    eager: tf.Tensor = ragged.to_tensor(default_value=0, shape=[None, 1])  # 0 is the value of the padding token\n",
        "    sqeezed: tf.Tensor = tf.squeeze(eager, axis=1)\n",
        "    typed: tf.Tensor = tf.cast(sqeezed, tf.int32)\n",
        "    edited: tf.Tensor = tf.concat([starts, typed, ends], axis=0)\n",
        "    return edited"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 381
        },
        "id": "UzHmzHSukp3a",
        "outputId": "0c7869e0-6d48-4f10-b9b0-84b4344c8876",
        "pycharm": {
          "name": "#%%\n"
        }
      },
      "outputs": [],
      "source": [
        "tokenized_data: List[tf.Tensor] = [tokenize_string(data_point) for data_point in tqdm.tqdm(data_list)] \n",
        "\n",
        "# tqdm is a progress bar"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 201
        },
        "id": "CNEdwxWFkp3d",
        "outputId": "36c5f35a-2398-442f-9736-bf7a08d4529c",
        "pycharm": {
          "name": "#%%\n"
        }
      },
      "outputs": [],
      "source": [
        "print(len(tokenized_data))\n",
        "print(tokenized_data[0].shape)\n",
        "print(tokenized_data[0][:10])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 404
        },
        "id": "D77Pm-iGkp3j",
        "outputId": "d08952c8-f333-4f21-8203-c49c6c2b7d9d",
        "pycharm": {
          "name": "#%%\n"
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "25315\n",
            "178\n"
          ]
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 360x360 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "lengths_tokenized: List[int] = [text.shape[0] for text in tokenized_data]\n",
        "print(max(lengths_tokenized))\n",
        "print(min(lengths_tokenized))\n",
        "sns.displot(lengths_tokenized, background='black', color='blue');"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5hNxIc9lVMMI",
        "outputId": "49100905-c0af-4366-ae66-ce43b3306d80",
        "pycharm": {
          "name": "#%% md\n"
        }
      },
      "source": [
        "This is a plot of the distribution of the lengths of the tokenized data (AKA how many tokens in each data point of the data set).\n",
        "We can see that there is very few data points with length over 8192 (2^13).\n",
        "A model that can handle long texts is very expensive (both in emory and runtime).\n",
        "Therefore I will filter out all texts longer than 8192 tokens.\n",
        "Note that 8192 is also a lot compared to the capacity of similar sized transformers."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "id": "EtjxgLWMkp3l"
      },
      "source": [
        "### chunk too long texts"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MubdHBEMkJNC"
      },
      "outputs": [],
      "source": [
        "def chunk_tensor(tensor: tf.Tensor, max_len: int = max_seq_len) -> List[tf.Tensor]:\n",
        "    \"\"\"Splits 1d tensor to chunks (1d tensors) of maximum size: max_len\"\"\"\n",
        "    return [tensor[i*max_len:(i+1)*max_len] for i in range(tensor.shape[0] // max_len)]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9DgU2Or2kp3m",
        "outputId": "292cd0f6-29ed-4cba-e627-4691f18955a7",
        "pycharm": {
          "name": "#%%\n"
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "102768\n",
            "(670,)\n"
          ]
        }
      ],
      "source": [
        "chunked_data: List[tf.Tensor] = []\n",
        "for tensor in tokenized_data:\n",
        "    chunks = chunk_tensor(tensor, max_seq_len)\n",
        "    for chunk in chunks:\n",
        "        chunked_data.append(chunk)\n",
        "DATA_SIZE: int = len(chunked_data)\n",
        "print(DATA_SIZE)\n",
        "print(chunked_data[0].shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R8Z2_P2Lnke8"
      },
      "source": [
        "## Padding"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XUOVoGBfkp3p",
        "pycharm": {
          "name": "#%%\n"
        }
      },
      "outputs": [],
      "source": [
        "def pad(tensor: tf.Tensor) -> tf.Tensor:\n",
        "    \"\"\"Pads the tensor to the length of the longest text in the data set\"\"\"\n",
        "    padded: tf.Tensor = tf.pad(tensor=tensor, paddings=[[0, max_seq_len - tensor.shape[0]]], mode='CONSTANT', constant_values=0)\n",
        "    # 0 is the padding token\n",
        "    return padded"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nRa9_ryHkp3p",
        "outputId": "3f8d82e6-6067-4bc3-a34c-54f6001636e2",
        "pycharm": {
          "name": "#%%\n"
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tf.Tensor([   2 1011 7670 ...    0    0    0], shape=(1024,), dtype=int32)\n"
          ]
        }
      ],
      "source": [
        "padded_data: List[tf.Tensor] = [pad(text) for text in chunked_data]\n",
        "print(padded_data[0])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "id": "gbnub0UZkp3s"
      },
      "source": [
        "## Train test val split"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7dz5c-Gskp3t",
        "pycharm": {
          "name": "#%%\n"
        }
      },
      "outputs": [],
      "source": [
        "random.shuffle(padded_data)\n",
        "train_size: int = int(DATA_SIZE * 0.8)\n",
        "val_test_size: int = int(DATA_SIZE * 0.1)  # Both validation and test get 10% of the data\n",
        "\n",
        "train_tokenized: List[tf.Tensor] = padded_data[:train_size]\n",
        "val_tokenized: List[tf.Tensor] = padded_data[train_size:(val_test_size + train_size)]\n",
        "test_tokenized: List[tf.Tensor] = padded_data[(train_size + val_test_size):]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gYF0ns5Rkp3t",
        "pycharm": {
          "name": "#%%\n"
        }
      },
      "outputs": [],
      "source": [
        "def list_to_dataset(tokenized_list: List[tf.Tensor]) -> tf.data.Dataset:\n",
        "    \"\"\"Converts a list of tokenized texts after all preprocessing to a tf.data.Dataset\"\"\"\n",
        "    dataset: tf.data.Dataset = tf.data.Dataset.from_tensor_slices(tokenized_list)\n",
        "    batched: tf.data.Dataset = dataset.batch(batch_size)\n",
        "    return batched\n",
        "\n",
        "train_set: tf.data.Dataset = list_to_dataset(train_tokenized)\n",
        "val_set: tf.data.Dataset = list_to_dataset(val_tokenized)\n",
        "test_set: tf.data.Dataset = list_to_dataset(test_tokenized)\n",
        "\n",
        "list_train_set = list(train_set)\n",
        "list_val_set = list(val_set)\n",
        "list_test_set = list(test_set)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HzS72rcIvL0N"
      },
      "source": [
        "## Clear memory"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VlkhQigKvOQT"
      },
      "outputs": [],
      "source": [
        "del train_tokenized, test_tokenized, val_tokenized\n",
        "del padded_data, chunked_data, tokenized_data, data_list, df, lengths_tokenized, \n",
        "del string_lengths, lookup_table\n",
        "del train_set, val_set, test_set"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5vBLynXu0QI1"
      },
      "source": [
        "# Model\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A9qUAZ00xiVd"
      },
      "source": [
        "## Positional encoding"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "id": "_V1b_16-kp3v"
      },
      "source": [
        "The formula for calculating the positional encoding is as follows:\n",
        "\n",
        "$${PE_{(pos, 2i)} = \\sin(pos / 10000^{2i / d_{model}})} $$\n",
        "$${PE_{(pos, 2i+1)} = \\cos(pos / 10000^{2i / d_{model}})} $$\n",
        "\n",
        "where $d_{model}$ is the model dimension, $pos$ is the position and $i$ is the index of the embedding.\n",
        "this is taken from the paper: attention is all you need."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "Wx4hze4k0yls"
      },
      "outputs": [],
      "source": [
        "def create_positional_encoding(max_len: int, d_model: int) -> tf.Tensor:\n",
        "    \"\"\"Returns the positional encoding for a given a maximal sequence length and model dimension.\n",
        "    inputs: max_len: int, d_model: int\n",
        "    returns: tf.Tensor of shape () and dtype tf.keras.backend.floatx()\"\"\"\n",
        "\n",
        "    def get_angles(positions: np.ndarray, timestamps: np.ndarray, d_model: int) -> np.ndarray:\n",
        "        \"\"\"Returns the angle in radians for given positions, timestamps and the dimension of the model\n",
        "        input: positions: np.ndarray of shape (max_len, 1), timestamps: np.ndarray of shape (1, d_model), d_model: int\n",
        "        output: np.ndarray of shape (max_len, d_model)\"\"\"\n",
        "        if tf.keras.backend.floatx() == \"float32\":\n",
        "            angle_rates = 1 / np.power(10000, ((2 * (timestamps//2)) / np.float32(d_model)))\n",
        "        else:\n",
        "            angle_rates = 1 / np.power(10000, ((2 * (timestamps//2)) / np.float16(d_model)))\n",
        "\n",
        "        return positions * angle_rates\n",
        "    \n",
        "    angle_rads = get_angles(np.arange(max_len)[:, np.newaxis],\n",
        "                            np.arange(d_model)[np.newaxis, :],\n",
        "                            d_model)  # (max_len, d_model)\n",
        "\n",
        "    # apply sin to even indices in the array; 2i\n",
        "    angle_rads[:, 0::2] = np.sin(angle_rads[:, 0::2])  # (max_len, d_model)\n",
        "\n",
        "    # apply cos to odd indices in the array; 2i+1\n",
        "    angle_rads[:, 1::2] = np.cos(angle_rads[:, 1::2])  # (max_len, d_model)\n",
        "\n",
        "    pos_encode = angle_rads[np.newaxis, ...]  # (1, max_len, d_model)\n",
        "\n",
        "    return tf.cast(pos_encode, dtype=tf.keras.backend.floatx())[:, :max_len, :]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QRzRM7eA01X0"
      },
      "outputs": [],
      "source": [
        "# n, d = 2048, 512\n",
        "# pos_encoding = create_positional_encoding(n, d)\n",
        "# print(pos_encoding.shape)\n",
        "# print(pos_encoding)\n",
        "# print(tf.reduce_min(pos_encoding))\n",
        "# print(tf.reduce_max(pos_encoding))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6ib5F3hnxrE9"
      },
      "source": [
        "## Masking"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3TXw70UlzcVi"
      },
      "source": [
        "Mask all the pad tokens in the batch of sequence. It ensures that the model does not treat padding as the input. The mask indicates where pad value 0 is present: it outputs a 1 at those locations, and a 0 otherwise."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4w68l26GzrqG"
      },
      "source": [
        "The look-ahead mask is used to mask the future tokens in a sequence. In other words, the mask indicates which entries should not be used.\n",
        "\n",
        "This means that to predict the third token, only the first and second token will be used. Similarly to predict the fourth token, only the first, second and the third tokens will be used and so on."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BQkjgUVVckzJ"
      },
      "outputs": [],
      "source": [
        "def create_masks(inp: tf.Tensor, tar: tf.Tensor) -> Tuple[tf.Tensor, tf.Tensor]:\n",
        "        \"\"\"Creates all the masks needed for the model\n",
        "        input: inp: tf.Tensor of shape (batch_size, seq_len), tar: tf.Tensor of shape (batch_size, set_size)\n",
        "        Returns: Tuple of (padding_mask, look_ahead_mask)\n",
        "        padding_mask: tf.Tensor of shape (batch_size, 1, 1, seq_len)\n",
        "        look_ahead_mask: tf.Tensor of shape (batch_size, 1, 1, set_size)\"\"\"\n",
        "        \n",
        "        def create_padding_mask(seq: tf.Tensor) -> tf.Tensor:\n",
        "                \"\"\"Returns a padding mask for the given sequence.\n",
        "                input: seq: tf.Tensor of shape (batch_size, seq_len)\n",
        "                Returns: tf.Tensor of shape (batch_size, seq_len, 1)\"\"\"\n",
        "                seq = tf.cast(tf.math.equal(seq, 0), tf.keras.backend.floatx())\n",
        "\n",
        "                # add extra dimensions to add the padding\n",
        "                \n",
        "                return seq[:, tf.newaxis, tf.newaxis, :]  # (batch_size, 1, 1, seq_len)\n",
        "        \n",
        "        # Encoder padding mask\n",
        "        padding_mask: tf.Tensor = create_padding_mask(inp)  # (batch_size, 1, 1, seq_len)\n",
        "\n",
        "        # Used in the 1st attention block in the decoder.\n",
        "        # It is used to pad and mask future tokens in the input received by\n",
        "        # the decoder.\n",
        "        set_size: int = tar.shape[1]\n",
        "\n",
        "        def create_look_ahead_mask(set_size: int) -> tf.Tensor:\n",
        "                mask = 1 - tf.linalg.band_part(tf.ones((set_size, set_size)), -1, 0)\n",
        "                mask = tf.cast(mask, dtype=tf.keras.backend.floatx())\n",
        "                return mask  # (seq_len, seq_len)\n",
        "\n",
        "        look_ahead_mask = create_look_ahead_mask(set_size)  # (seq_len, seq_len)\n",
        "        dec_target_padding_mask = create_padding_mask(tar)  # (batch_size, 1, 1, seq_len)\n",
        "        look_ahead_mask = tf.maximum(dec_target_padding_mask, look_ahead_mask)\n",
        "\n",
        "        return padding_mask, look_ahead_mask"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9KHKaxz3xumc"
      },
      "source": [
        "## Layers and blocks"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "class ScaledDotProductAttention(tf.keras.layers.Layer):\n",
        "    def __init__(self, d_model: int, **kwargs):\n",
        "        super().__init__(**kwargs)\n",
        "        self.scale: tf.TensorSpec(shape=(), dtype=tf.keras.backend.floatx())\n",
        "        # scale = 1 / sqrt(d_model)\n",
        "        self.scale = tf.math.pow(tf.cast(d_model, tf.keras.backend.floatx()), -0.5)\n",
        "\n",
        "    def call(self, q: tf.Tensor, k: tf.Tensor, v: tf.Tensor, mask: Optional[tf.Tensor] = None) -> tf.Tensor:\n",
        "        \"\"\"Scaled Dot-Product Attention\n",
        "        input: \n",
        "        q: tf.Tensor of shape (batch_size, seq_len, d_model), \n",
        "        k: tf.Tensor of shape (batch_size, seq_len, d_model), \n",
        "        v: tf.Tensor of shape (batch_size, seq_len, d_model), \n",
        "        mask: Optional[tf.Tensor] of shape (batch_size, seq_len)\n",
        "        output: tf.Tensor of shape (batch_size, seq_len, d_model)\"\"\"\n",
        "        matmul_qk: tf.Tensor = tf.matmul(q, k, transpose_b=True)  # (..., seq_len_q, seq_len_k)\n",
        "\n",
        "        # Scaled Dot-Product Attention\n",
        "        scaled_attention_logits: tf.Tensor = matmul_qk * self.scale  # (..., seq_len_q, seq_len_k)\n",
        "        # matmul_qk / sqrt(d_model)\n",
        "\n",
        "        # Masking\n",
        "        if mask is not None:\n",
        "            # noinspection PyTypeChecker\n",
        "            if tf.keras.backend.floatx() == 'float16':\n",
        "                # tf.float16.min is minus infinity\n",
        "                scaled_attention_logits += (mask * tf.float16.min)  # changed from -1e9 to prevent nan's\n",
        "            else:\n",
        "                scaled_attention_logits += (mask * -1e9) \n",
        "\n",
        "        # Normalize\n",
        "        attention_weights = tf.keras.layers.softmax(scaled_attention_logits, axis=-1)\n",
        "\n",
        "        # Output\n",
        "        output = tf.matmul(attention_weights, v)\n",
        "\n",
        "        return output"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_0I9SZI0kp31",
        "pycharm": {
          "name": "#%%\n"
        }
      },
      "outputs": [],
      "source": [
        "class MyMultiHeadAttention(tf.keras.layers.Layer):\n",
        "    \"\"\"U can use the built-in tf.keras.layers.multihead_attention but is caused a bug for me\"\"\"\n",
        "    def __init__(self, num_heads: int, d_model: int, **kwargs):\n",
        "        super(MyMultiHeadAttention, self).__init__(**kwargs)\n",
        "        if d_model % num_heads != 0:\n",
        "            raise ValueError(f\"d_model ({d_model}) must be divisible by num_heads ({num_heads})\")\n",
        "        self.num_heads = num_heads\n",
        "        self.d_model = d_model\n",
        "\n",
        "        self.depth = d_model // self.num_heads\n",
        "\n",
        "        self.wq = tf.keras.layers.Dense(d_model)\n",
        "        self.wk = tf.keras.layers.Dense(d_model)\n",
        "        self.wv = tf.keras.layers.Dense(d_model)\n",
        "\n",
        "        self.dense = tf.keras.layers.Dense(d_model)\n",
        "\n",
        "        self.sdpa = ScaledDotProductAttention()\n",
        "\n",
        "    def split_heads(self, x: tf.Tensor, batch_size: int) -> tf.Tensor:\n",
        "        \"\"\"Split the last dimension into (num_heads, depth).\n",
        "        Transpose the result such that the shape is (batch_size, num_heads, seq_len, depth)\n",
        "        \"\"\"\n",
        "        x = tf.reshape(x, (batch_size, -1, self.num_heads, self.depth))\n",
        "        return tf.transpose(x, perm=[0, 2, 1, 3])\n",
        "\n",
        "    def call(self, v_k: tf.Tensor, q: tf.Tensor, mask: tf.Tensor) -> tf.Tensor:\n",
        "        \"\"\"inputs:\n",
        "        v_k: tf.Tensor of shape (batch_size, seq_len, d_model) in self attention keys and values are the same\n",
        "        q: tf.Tensor of shape (batch_size, seq_len, d_model)\n",
        "        mask: Optional[tf.Tensor] of shape (batch_size, seq_len)\"\"\"\n",
        "        batch_size = tf.shape(q)[0]\n",
        "\n",
        "        q: tf.Tensor = self.wq(q)  # (batch_size, seq_len, d_model)\n",
        "        k: tf.Tensor = self.wk(v_k)  # (batch_size, seq_len, d_model)\n",
        "        v: tf.Tensor = self.wv(v_k)  # (batch_size, seq_len, d_model)\n",
        "\n",
        "        q: tf.Tensor = self.split_heads(q, batch_size)  # (batch_size, num_heads, seq_len_q, depth)\n",
        "        k: tf.Tensor = self.split_heads(k, batch_size)  # (batch_size, num_heads, seq_len_k, depth)\n",
        "        v: tf.Tensor = self.split_heads(v, batch_size)  # (batch_size, num_heads, seq_len_v, depth)\n",
        "\n",
        "        # scaled_attention.shape should be (batch_size, num_heads, seq_len_q, depth)\n",
        "        # attention_weights.shape should be (batch_size, num_heads, seq_len_q, seq_len_k)\n",
        "        scaled_attention = self.sdpa(q, k, v, mask)\n",
        "\n",
        "        scaled_attention = tf.transpose(scaled_attention, perm=[0, 2, 1, 3]) \n",
        "         # (batch_size, seq_len_q, num_heads, depth)\n",
        "\n",
        "        concat_attention = tf.reshape(scaled_attention, (batch_size, -1, self.d_model))\n",
        "          # (batch_size, seq_len_q, d_model)\n",
        "\n",
        "        output = self.dense(concat_attention)  # (batch_size, seq_len_q, d_model)\n",
        "\n",
        "        return output"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "class PointWiseFeedForwardNetwork(tf.keras.layers.Layer):\n",
        "    def __init__(self, d_model: int, dff: int, **kwargs): \n",
        "        super(PointWiseFeedForwardNetwork).__init__(**kwargs)\n",
        "        self.layer1 = tf.keras.layers.Dense(dff, activation='relu'),  # (batch_size, seq_len, dff)\n",
        "        self.layer2 = tf.keras.layers.Dense(d_model)  # (batch_size, seq_len, d_model)\n",
        "    \n",
        "    def call(self, x: tf.Tensor) -> tf.Tensor:\n",
        "        return self.layer2(self.layer1(x))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8mEP3-Jx2n39"
      },
      "outputs": [],
      "source": [
        "class EncoderBlock(tf.keras.layers.Layer):\n",
        "    def __init__(self, d_model: int, num_heads: int, dff: int, rate: float, **kwargs):\n",
        "        super(EncoderBlock, self).__init__(**kwargs)\n",
        "\n",
        "        self.mha = MyMultiHeadAttention(num_heads = num_heads, d_model = d_model)\n",
        "        self.ffn = PointWiseFeedForwardNetwork(d_model, dff)\n",
        "\n",
        "        self.layer_norm = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
        "\n",
        "        self.dropout = tf.keras.layers.Dropout(rate)\n",
        "\n",
        "    def call(self, x: tf.Tensor, training, mask: tf.Tensor) -> tf.Tensor:\n",
        "        \n",
        "        attn_output = self.mha(x, x, mask)  # (batch_size, input_seq_len, d_model)\n",
        "        attn_output = self.dropout(attn_output, training=training)\n",
        "        out1 = self.layer_norm(x + attn_output)  # (batch_size, input_seq_len, d_model)\n",
        "        \n",
        "        ffn_output = self.ffn(out1)  # (batch_size, input_seq_len, d_model)\n",
        "        ffn_output = self.dropout(ffn_output, training=training)\n",
        "        out2 = self.layer_norm(out1 + ffn_output)  # (batch_size, input_seq_len, d_model)\n",
        "\n",
        "        return out2\n",
        "        "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "xJWFrv0g281G"
      },
      "outputs": [],
      "source": [
        "class DecoderBlock(tf.keras.layers.Layer):\n",
        "    # __slots__ = [\"mha\", \"ffn\", \"layer_norm\", \"dropout\"]\n",
        "    def __init__(self, d_model: int, num_heads: int, dff: int, rate: float, **kwargs):\n",
        "        super(DecoderBlock, self).__init__(**kwargs)\n",
        "\n",
        "        self.mha = MyMultiHeadAttention(num_heads = num_heads, d_model = d_model)\n",
        "\n",
        "        self.ffn = PointWiseFeedForwardNetwork(d_model, dff)\n",
        "\n",
        "        self.layer_norm = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
        "\n",
        "        self.dropout = tf.keras.layers.Dropout(rate)\n",
        "\n",
        "    def call(self, x: tf.Tensor, enc_output: tf.Tensor, look_ahead_mask: tf.Tensor, padding_mask: tf.Tensor, training):\n",
        "        # enc_output.shape should be (batch_size, input_seq_len, d_model)\n",
        "\n",
        "        attn1 = self.mha(x, x, look_ahead_mask)  # (batch_size, set_size, d_model)\n",
        "        attn1 = self.dropout(attn1, training=training)\n",
        "        out1 = self.layer_norm(attn1 + x)\n",
        "\n",
        "        attn2 = self.mha(enc_output, out1, padding_mask)  # (batch_size, set_size, d_model)\n",
        "        attn2 = self.dropout(attn2, training=training)\n",
        "        out2 = self.layer_norm(attn2 + out1)  # (batch_size, set_size, d_model)\n",
        "\n",
        "        ffn_output = self.ffn(out2)  # (batch_size, set_size, d_model)\n",
        "        ffn_output = self.dropout(ffn_output, training=training)\n",
        "        out3 = self.layer_norm(ffn_output + out2)  # (batch_size, set_size, d_model)\n",
        "\n",
        "        return out3\n",
        "        "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NdlS1kfM3k5d"
      },
      "outputs": [],
      "source": [
        "class Encoder(tf.keras.layers.Layer):\n",
        "    def __init__(self, pos_encoding: tf.Tensor, num_blocks: int, d_model: int, num_heads: int, dff: int, rate=0.1, **kwargs):\n",
        "        super(Encoder, self).__init__(**kwargs)\n",
        "\n",
        "        self.d_model = d_model\n",
        "        self.num_blocks = num_blocks\n",
        "        self.pos_encoding = pos_encoding\n",
        "\n",
        "        self.enc_blocks = [EncoderBlock(d_model, num_heads, dff, rate) for _ in range(num_blocks)]\n",
        "        # the encoder \n",
        "        self.dropout = tf.keras.layers.Dropout(rate)\n",
        "\n",
        "    def call(self, x: tf.Tensor, training, mask: tf.Tensor) -> tf.Tensor:\n",
        "\n",
        "        seq_len = tf.shape(x)[1]\n",
        "\n",
        "        # adding position encoding.\n",
        "        x *= tf.math.sqrt(tf.cast(self.d_model, tf.keras.backend.floatx()))\n",
        "        \n",
        "        x += self.pos_encoding\n",
        "        x = self.dropout(x, training=training)\n",
        "\n",
        "        for i in range(self.num_blocks):\n",
        "            x = self.enc_blocks[i](x, training, mask)\n",
        "\n",
        "        return x  # (batch_size, input_seq_len, d_model)\n",
        "        "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QLE8js6O3p5-"
      },
      "outputs": [],
      "source": [
        "class Decoder(tf.keras.layers.Layer):\n",
        "    def __init__(self, pos_encoding, num_blocks: int, d_model: int, num_heads: int, dff: int,\n",
        "                 vocab_size: int, rate: float, **kwargs):\n",
        "        super(Decoder, self).__init__(**kwargs)\n",
        "\n",
        "        self.d_model = d_model\n",
        "        self.num_blocks = num_blocks\n",
        "        self.pos_encoding = pos_encoding\n",
        "\n",
        "        self.embedding = tf.keras.layers.Embedding(vocab_size, d_model)\n",
        "        self.dec_layers = [DecoderBlock(d_model, num_heads, dff, rate) for _ in range(num_blocks)]\n",
        "        self.dropout = tf.keras.layers.Dropout(rate)\n",
        "\n",
        "    def call(self, x: tf.Tensor, enc_output: tf.Tensor, training: bool,\n",
        "             look_ahead_mask: tf.Tensor, padding_mask: tf.Tensor) -> tf.Tensor:\n",
        "\n",
        "        seq_len = tf.shape(x)[1]\n",
        "\n",
        "        x = self.embedding(x)  # (batch_size, set_size, d_model)\n",
        "        x *= tf.math.sqrt(tf.cast(self.d_model, tf.keras.backend.floatx()))\n",
        "        x += self.pos_encoding\n",
        "\n",
        "        x = self.dropout(x, training=training)\n",
        "\n",
        "        for i in range(self.num_blocks):\n",
        "            x = self.dec_layers[i](x=x, enc_output=enc_output, look_ahead_mask=look_ahead_mask, \n",
        "                                   padding_mask=padding_mask, training=training)\n",
        "\n",
        "        # x.shape should be (batch_size, set_size, d_model)\n",
        "        return x\n",
        "        "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1-xe3K7LyD2l"
      },
      "source": [
        "## The full model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4NLhyE0T3tUs"
      },
      "outputs": [],
      "source": [
        "class SeTransformer(tf.keras.Model):\n",
        "    \"\"\"The base architecture of my models in this project.\"\"\"\n",
        "    def __init__(self, num_blocks: int, d_model: int, num_heads: int, dff: int,\n",
        "                 vocab_size: int, max_len: int, rate: float, **kwargs):\n",
        "        super(SeTransformer).__init__(**kwargs)  # calls tf.keras.Model's __init__ method\n",
        "        pos_encoding = create_positional_encoding(max_len, d_model)\n",
        "\n",
        "        self.encoder = Encoder(pos_encoding, num_blocks, d_model, num_heads, dff, rate)\n",
        "        self.decoder = Decoder(pos_encoding, num_blocks, d_model, num_heads, dff, vocab_size, rate)\n",
        "\n",
        "        self.embedding = tf.keras.layers.Embedding(vocab_size, d_model)\n",
        "        self.dense = tf.keras.layers.Dense(vocab_size)\n",
        "        self.softmax = tf.keras.layers.Softmax(axis = -1)  # there are {vocab_size} categories in the output\n",
        "\n",
        "    def call(self, inputs: List[tf.Tensor], training: bool) -> tf.Tensor:\n",
        "        inp, tar = inputs\n",
        "        # inp.shape should be (batch_size, max_seq_len) or (1, max_seq_len)\n",
        "        # tar.shape should be (batch_size, set_size) or (1, set_size)\n",
        "        padding_mask, look_ahead_mask = create_masks(inp, tar)\n",
        "        x = self.embedding(inp)  # (batch_size, max_seq_len, d_model)\n",
        "        enc_output = self.encoder(x, training, padding_mask)  # (batch_size, max_seq_len, d_model)\n",
        "        \n",
        "        # dec_output.shape should be (batch_size, set_size, d_model)\n",
        "        dec_output = self.decoder(tar, enc_output, training, look_ahead_mask, padding_mask)\n",
        "\n",
        "        final_output = self.dense(dec_output)\n",
        "        # final_output.shape should be (batch_size, set_size, vocab_size)\n",
        "        softmaxed = self.softmax(final_output)\n",
        "        # softmaxed.shape should be (batch_size, set_size, vocab_size)\n",
        "        return softmaxed\n",
        "        "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3WZ41cb-1B_f",
        "outputId": "6ee5ceb5-2868-4ea0-b38a-5948f88a3704"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(16, 4, 8192)\n",
            "tf.Tensor(\n",
            "[[1.4842e-04 9.7454e-05 1.1861e-04 ... 1.1611e-04 1.2434e-04 1.1706e-04]\n",
            " [1.3661e-04 1.0204e-04 1.2231e-04 ... 1.2231e-04 1.3041e-04 1.2803e-04]\n",
            " [1.4734e-04 9.5904e-05 1.2481e-04 ... 1.1802e-04 1.1986e-04 1.1879e-04]\n",
            " [1.4484e-04 9.9003e-05 1.2088e-04 ... 1.1575e-04 1.2064e-04 1.2141e-04]], shape=(4, 8192), dtype=float16)\n"
          ]
        }
      ],
      "source": [
        "sample_transformer = SeTransformer(\n",
        "    num_blocks=2, d_model=32, num_heads=4, dff=128,\n",
        "    vocab_size=VOCAB_SIZE,\n",
        "    max_len=max_seq_len)\n",
        "\n",
        "temp_input = tf.random.uniform((batch_size, max_seq_len), dtype=tf.int32, minval=0, maxval=VOCAB_SIZE-1)\n",
        "temp_target = tf.random.uniform((batch_size, set_size), dtype=tf.int32, minval=0, maxval=VOCAB_SIZE-1)\n",
        "\n",
        "fn_out = sample_transformer([temp_input, temp_target], training=True)\n",
        "\n",
        "print(fn_out.shape)  # (batch_size, set_size, VOCAB_SIZE)\n",
        "print(fn_out[0])\n",
        "del sample_transformer"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "id": "hFxiRfCekp38"
      },
      "source": [
        "# Training the model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "id": "8jsueeI0kp3-"
      },
      "source": [
        "## Optimizer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yZ8vqihqkp3-",
        "pycharm": {
          "name": "#%%\n"
        }
      },
      "outputs": [],
      "source": [
        "optimizer = tf.keras.optimizers.Adam(learning_rate, beta_1=0.9, beta_2=0.98, epsilon=tf.float16.min)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O783T1xMckzR"
      },
      "source": [
        "## Create the model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-uAxXGBtkp4A",
        "pycharm": {
          "name": "#%%\n"
        }
      },
      "outputs": [],
      "source": [
        "model = SeTransformer(\n",
        "    num_blocks=num_blocks,\n",
        "    d_model=d_model,\n",
        "    num_heads=num_heads,\n",
        "    dff=dff,\n",
        "    vocab_size=VOCAB_SIZE,\n",
        "    max_len=max_seq_len,\n",
        "    rate=dropout_rate)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5gjCRldwckzR"
      },
      "source": [
        "## Train step function"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PQg2vNCNjUIJ"
      },
      "source": [
        "Since I can't use model.compile and model.fit and I dont want this function to be compiled every time I run it, I use tf.function to pre-compile the function into tf.graph"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FaBpjXbnqSBD"
      },
      "outputs": [],
      "source": [
        "@tf.function(input_signature=[tf.TensorSpec(shape=[batch_size, set_size], dtype = tf.int32)])\n",
        "def tokens_to_onehot(tokens: tf.Tensor):\n",
        "    \"\"\"Gets a tokens tensor of shape: (batch_size, set_size) and dtype: tf.int32\n",
        "     and returns a onehot encoding tensor of shape: (batch_size, set_size, VOCAB_SIZE) \n",
        "     and dtype: tf.int32\"\"\"\n",
        "    # probably a bottleneck\n",
        "    one_hot = tf.one_hot(tokens, depth = VOCAB_SIZE, axis=-1)\n",
        "    return tf.cast(one_hot, tf.int32)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XBqe_-AS6KCa"
      },
      "outputs": [],
      "source": [
        "loss_func = tf.keras.losses.CategoricalCrossentropy()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UR6qYltHhh_t"
      },
      "outputs": [],
      "source": [
        "@tf.function(input_signature=[tf.TensorSpec(shape=[batch_size, None], dtype=tf.int32),\n",
        "                              tf.TensorSpec(shape=[batch_size, set_size], dtype=tf.int32)])\n",
        "def train_step(inp: tf.Tensor, outp: tf.Tensor) -> tf.Tensor:\n",
        "    with tf.GradientTape() as tape:\n",
        "        pred: tf.Tensor = model([inp, outp], training=True)\n",
        "        \n",
        "        expected: tf.Tensor = tokens_to_onehot(outp)\n",
        "        loss_val: tf.Tensor = loss_func(y_true = expected, y_pred = pred)\n",
        "    grads: tf.Tensor = tape.gradient(loss_val, model.trainable_weights)\n",
        "    optimizer.apply_gradients(zip(grads, model.trainable_weights))\n",
        "    return loss_val"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mUM4zxGtckzS",
        "pycharm": {
          "name": "#%%\n"
        }
      },
      "outputs": [],
      "source": [
        "@tf.function(input_signature=[tf.TensorSpec(shape=[batch_size, None], dtype=tf.int32),\n",
        "                              tf.TensorSpec(shape=[batch_size, set_size], dtype=tf.int32)])\n",
        "def val_step(inp: tf.Tensor, outp: tf.Tensor) -> tf.Tensor:\n",
        "    pred = model([inp, outp], training=False)\n",
        "    expected = tokens_to_onehot(outp)\n",
        "    loss: tf.Tensor = loss_func(y_true = expected, y_pred = pred)\n",
        "    return loss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7NpdkcUkckzT",
        "pycharm": {
          "name": "#%%\n"
        }
      },
      "outputs": [],
      "source": [
        "def validate(batch: tf.Tensor) -> float:\n",
        "    per_generation_loss: List[float] = []\n",
        "    for i in range(NUM_SETS):\n",
        "        # The input is of size set_size-TAKE_TO_ACCOUNT\n",
        "        already_predicted: int = i*(set_size+1)\n",
        "        start_from: int = max(0, already_predicted - max_seq_len)\n",
        "        inp: tf.Tensor = batch[:, start_from:(i + 1) * set_size]\n",
        "        outp: tf.Tensor = batch[:, (i + 1) * set_size:(i + 2) * set_size]\n",
        "        loss_val: tf.Tensor = val_step(inp, outp)\n",
        "        float_loss: float = loss_val.numpy().item()\n",
        "        per_generation_loss.append(float_loss)\n",
        "    return sum(per_generation_loss) / len(per_generation_loss)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "j8944E1hckzT",
        "pycharm": {
          "name": "#%%\n"
        }
      },
      "outputs": [],
      "source": [
        "def delete_last_row(csv_path: str):\n",
        "    \"\"\"Deletes the last row of a csv file\"\"\"\n",
        "    with open(csv_path, 'r') as f:\n",
        "        lines = f.readlines()[:-1]\n",
        "    with open(csv_path, 'w') as f:\n",
        "        c_writer = csv.writer(f, delimiter=',')\n",
        "        for line in lines:\n",
        "            c_writer.writerow(line)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LZsEGz_vckzT",
        "pycharm": {
          "name": "#%%\n"
        }
      },
      "outputs": [],
      "source": [
        "def check_point(folder_path: str, model: SeTransformer, val_loss: float, train_loss: float):\n",
        "    \"\"\"Saves the model at the end of each epoch\"\"\"\n",
        "    path: str = f\"{folder_path}/\"\n",
        "    tf.keras.models.save_model(model = model, filepath = path, save_format='tf')\n",
        "    delete_last_row('experiments.csv')\n",
        "    fields = [date, val_loss, train_loss, set_size, num_blocks, d_model, dff,\n",
        "              num_heads, learning_rate, max_seq_len, dropout_rate, batch_size]\n",
        "    with open('experiments.csv', 'a') as f:\n",
        "        writer = csv.writer(f, delimiter=',')\n",
        "        writer.writerow(fields)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KQc_k2ekckzU"
      },
      "source": [
        "## The training loop itself"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Iuce_A94ckzU",
        "pycharm": {
          "name": "#%%\n"
        }
      },
      "outputs": [],
      "source": [
        "date: str = datetime.datetime.now().strftime('%m%d-%H%M')\n",
        "check_points_path = f\"/drive/MyDrive/checkpoints/{date}\"\n",
        "if not os.path.isdir(\"/drive/MyDrive/checkpoints\"):\n",
        "    os.mkdir(\"/drive/MyDrive/checkpoints\")\n",
        "if not os.path.isdir(check_points_path):\n",
        "    os.mkdir(check_points_path)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "id": "tDUBdOH0ckzV"
      },
      "source": [
        "## Add row to experiment.csv"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "00auA3LZwKvf"
      },
      "outputs": [],
      "source": [
        "train_loss, val_loss = float('inf'), float('inf')\n",
        "best_val_loss = float('inf')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DWKTBdzkckzV",
        "pycharm": {
          "name": "#%%\n"
        }
      },
      "outputs": [],
      "source": [
        "with open(r'experiments.csv', 'a') as f:\n",
        "    fields = [date, val_loss, train_loss, set_size, num_blocks, d_model, dff,\n",
        "              num_heads, learning_rate, max_seq_len, dropout_rate, batch_size]\n",
        "    writer = csv.writer(f)\n",
        "    writer.writerow(fields)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RN8rmbrNW0-Z"
      },
      "source": [
        "# The actual training loop!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bvpXKOY-rKgN",
        "outputId": "12088668-d6cf-4d27-d5a4-3ac1086492b8"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(643, <tf.Tensor: shape=(16, 1024), dtype=int32, numpy=\n",
              " array([[1737,   50,  897, ...,  787,  307,   56],\n",
              "        [   2, 4200, 3656, ..., 5749,   46,   48],\n",
              "        [   5,   36, 2684, ..., 1751,  164,   51],\n",
              "        ...,\n",
              "        [   2,   35, 5157, ...,    7,   76, 1051],\n",
              "        [ 912, 2923,   53, ...,    0,    0,    0],\n",
              "        [1506,   51,   48, ..., 1334,  839,    6]], dtype=int32)>)"
            ]
          },
          "execution_count": 248,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "\n",
        "len(list_val_set), list_val_set[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nHktVH98kp4B",
        "outputId": "bd16ea4d-22d7-42d1-f603-27c4a82a6508",
        "pycharm": {
          "name": "#%%\n"
        }
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r0it [00:00, ?it/s]WARNING:absl:Found untraced functions such as embedding_56_layer_call_fn, embedding_56_layer_call_and_return_conditional_losses, dropout_211_layer_call_fn, dropout_211_layer_call_and_return_conditional_losses, embedding_57_layer_call_fn while saving (showing 5 of 136). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: ./checkpoints/2022-06-12/assets\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: ./checkpoints/2022-06-12/assets\n",
            "10it [01:03,  3.22s/it]WARNING:absl:Found untraced functions such as embedding_56_layer_call_fn, embedding_56_layer_call_and_return_conditional_losses, dropout_211_layer_call_fn, dropout_211_layer_call_and_return_conditional_losses, embedding_57_layer_call_fn while saving (showing 5 of 136). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: ./checkpoints/2022-06-12/assets\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: ./checkpoints/2022-06-12/assets\n",
            "20it [01:55,  3.18s/it]WARNING:absl:Found untraced functions such as embedding_56_layer_call_fn, embedding_56_layer_call_and_return_conditional_losses, dropout_211_layer_call_fn, dropout_211_layer_call_and_return_conditional_losses, embedding_57_layer_call_fn while saving (showing 5 of 136). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: ./checkpoints/2022-06-12/assets\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: ./checkpoints/2022-06-12/assets\n",
            "30it [02:49,  3.14s/it]WARNING:absl:Found untraced functions such as embedding_56_layer_call_fn, embedding_56_layer_call_and_return_conditional_losses, dropout_211_layer_call_fn, dropout_211_layer_call_and_return_conditional_losses, embedding_57_layer_call_fn while saving (showing 5 of 136). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: ./checkpoints/2022-06-12/assets\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: ./checkpoints/2022-06-12/assets\n",
            "40it [03:41,  3.14s/it]WARNING:absl:Found untraced functions such as embedding_56_layer_call_fn, embedding_56_layer_call_and_return_conditional_losses, dropout_211_layer_call_fn, dropout_211_layer_call_and_return_conditional_losses, embedding_57_layer_call_fn while saving (showing 5 of 136). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: ./checkpoints/2022-06-12/assets\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: ./checkpoints/2022-06-12/assets\n",
            "50it [04:37,  3.35s/it]WARNING:absl:Found untraced functions such as embedding_56_layer_call_fn, embedding_56_layer_call_and_return_conditional_losses, dropout_211_layer_call_fn, dropout_211_layer_call_and_return_conditional_losses, embedding_57_layer_call_fn while saving (showing 5 of 136). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: ./checkpoints/2022-06-12/assets\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: ./checkpoints/2022-06-12/assets\n",
            "60it [05:32,  3.17s/it]WARNING:absl:Found untraced functions such as embedding_56_layer_call_fn, embedding_56_layer_call_and_return_conditional_losses, dropout_211_layer_call_fn, dropout_211_layer_call_and_return_conditional_losses, embedding_57_layer_call_fn while saving (showing 5 of 136). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: ./checkpoints/2022-06-12/assets\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: ./checkpoints/2022-06-12/assets\n",
            "70it [06:23,  3.08s/it]WARNING:absl:Found untraced functions such as embedding_56_layer_call_fn, embedding_56_layer_call_and_return_conditional_losses, dropout_211_layer_call_fn, dropout_211_layer_call_and_return_conditional_losses, embedding_57_layer_call_fn while saving (showing 5 of 136). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: ./checkpoints/2022-06-12/assets\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: ./checkpoints/2022-06-12/assets\n",
            "80it [07:16,  3.10s/it]WARNING:absl:Found untraced functions such as embedding_56_layer_call_fn, embedding_56_layer_call_and_return_conditional_losses, dropout_211_layer_call_fn, dropout_211_layer_call_and_return_conditional_losses, embedding_57_layer_call_fn while saving (showing 5 of 136). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: ./checkpoints/2022-06-12/assets\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: ./checkpoints/2022-06-12/assets\n",
            "90it [08:32,  3.33s/it]WARNING:absl:Found untraced functions such as embedding_56_layer_call_fn, embedding_56_layer_call_and_return_conditional_losses, dropout_211_layer_call_fn, dropout_211_layer_call_and_return_conditional_losses, embedding_57_layer_call_fn while saving (showing 5 of 136). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: ./checkpoints/2022-06-12/assets\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: ./checkpoints/2022-06-12/assets\n",
            "100it [10:25,  4.18s/it]WARNING:absl:Found untraced functions such as embedding_56_layer_call_fn, embedding_56_layer_call_and_return_conditional_losses, dropout_211_layer_call_fn, dropout_211_layer_call_and_return_conditional_losses, embedding_57_layer_call_fn while saving (showing 5 of 136). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: ./checkpoints/2022-06-12/assets\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: ./checkpoints/2022-06-12/assets\n"
          ]
        }
      ],
      "source": [
        "EPOCHS: int = 100  # Train until the cloud disconnects\n",
        "NUM_SETS: int = (max_seq_len // set_size) - 1 # Because we dont predict the first set\n",
        "per_epoch_train_loss: List[float] = []\n",
        "per_epoch_val_loss: List[float] = []\n",
        "check_points_path = f\"./checkpoints/{datetime.datetime.now().strftime('%Y-%m-%d')}\"\n",
        "if not os.path.isdir(check_points_path):\n",
        "    os.mkdir(check_points_path)\n",
        "for epoch in range(EPOCHS):\n",
        "    per_batch_train_loss: List[float] = []\n",
        "    per_batch_val_loss: List[float] = []\n",
        "    for batch_num, train_batch in tqdm.tqdm(enumerate(list_train_set)):  # tqdm is a progress bar\n",
        "        per_generation_loss: List[float] = []\n",
        "        for i in range(NUM_SETS):\n",
        "            # The input is of size set_size-TAKE_TO_ACCOUNT\n",
        "            already_predicted: int = i * (set_size + 1)\n",
        "            start_from: int = max(0, already_predicted - max_seq_len)\n",
        "            inp: tf.Tensor = train_batch[:, start_from:(i + 1) * set_size]\n",
        "            outp: tf.Tensor = train_batch[:, (i + 1) * set_size:(i + 2) * set_size]\n",
        "            loss_val: tf.Tensor = train_step(inp, outp)\n",
        "            train_loss: float = loss_val.numpy().item()\n",
        "            # assert isinstance(train_loss, float)\n",
        "            \n",
        "            per_generation_loss.append(train_loss)\n",
        "            \n",
        "        per_batch_train_loss.append(statistics.mean(per_generation_loss))\n",
        "        if batch_num % 10 == 0:\n",
        "            next_val_batch: tf.Tensor = list_val_set[batch_num // 10]\n",
        "            val_loss: float = validate(next_val_batch)\n",
        "            per_batch_val_loss.append(val_loss)\n",
        "            if val_loss < best_val_loss:\n",
        "                best_val_loss = val_loss\n",
        "                check_point(check_points_path, model, val_loss, train_loss)\n",
        "    per_epoch_train_loss.append(statistics.mean(per_batch_train_loss))\n",
        "    per_epoch_val_loss.append(statistics.mean(per_batch_val_loss))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Z1gVcN35kp4C",
        "pycharm": {
          "name": "#%%\n"
        }
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "5vBLynXu0QI1"
      ],
      "name": "create_models.ipynb",
      "provenance": []
    },
    "gpuClass": "standard",
    "kernel_info": {
      "name": "python3"
    },
    "kernelspec": {
      "display_name": "Python 3.9.12 ('base')",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.12"
    },
    "nteract": {
      "version": "nteract-front-end@1.0.0"
    },
    "vscode": {
      "interpreter": {
        "hash": "4c667eb41e29edd16195f2712b5916a29b36d4e6f17fe7c0a7edbb7a73b8ba8a"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
